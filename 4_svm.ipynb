{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98779557a508068a",
   "metadata": {},
   "source": [
    "# Classification using the Support Vector Machine (SVM) Algorithm\n",
    "|                  |                                                                                                                                                                                                     |\n",
    "|:-----------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Course Codes** | BBT 4106, BCM 3104, and BFS 4102                                                                                                                                                                    |\n",
    "| **Course Names** | BBT 4106: Business Intelligence I (Week 10-12 of 13),<br/>BCM 3104: Business Intelligence and Data Analytics (Week 10-12 of 13) and<br/>BFS 4102: Advanced Business Data Analytics (Week 4-6 of 13) |\n",
    "| **Semester**     | April to July 2025                                                                                                                                                                                  |\n",
    "| **Lecturer**     | Allan Omondi                                                                                                                                                                                        |\n",
    "| **Contact**      | aomondi@strathmore.edu                                                                                                                                                                              |\n",
    "| **Note**         | The lecture contains both theory and practice. This notebook forms part of the practice. This is intended for educational purpose only.                                                             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f4645b58c95cc",
   "metadata": {},
   "source": "## Step 1: Import the necessary libraries"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "# Import LabelEncoder for encoding categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Import train_test_split for splitting the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import resampling utilities for balancing the dataset\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa681e97ffbe68a9",
   "metadata": {},
   "source": [
    "## Step 2: Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "fbd4307324fa0888",
   "metadata": {},
   "source": [
    "# Load the dataset into a DataFrame\n",
    "# Description of dataset: https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset\n",
    "url = 'https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/data/online_shoppers_intention.csv'\n",
    "online_shoppers_intention_data = pd.read_csv(url)\n",
    "# online_shoppers_intention_data = pd.read_csv(\"./data/online_shoppers_intention.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1140bbfee73f325c",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd11c78ca98c70",
   "metadata": {},
   "source": [
    "We need to convert the data into a numeric format suitable for the model. First, we map the boolean Revenue target to integers (0 and 1). Then we encode any categorical variables into numeric form. In this dataset, columns like VisitorType, Weekend, and Month are categorical. We can use label encoding for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "id": "a6fbfd6080299c7d",
   "metadata": {},
   "source": [
    "# Map the target 'Revenue' from False/True to 0/1\n",
    "online_shoppers_intention_data['Revenue'] = online_shoppers_intention_data['Revenue'].map({False: 0, True: 1})\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the categorical columns: 'VisitorType', 'Weekend', and 'Month'\n",
    "online_shoppers_intention_data['VisitorType'] = le.fit_transform(online_shoppers_intention_data['VisitorType']) # e.g., 'Returning_Visitor'->1\n",
    "online_shoppers_intention_data['Weekend'] = le.fit_transform(online_shoppers_intention_data['Weekend']) # False->0, True->1\n",
    "online_shoppers_intention_data['Month']   = le.fit_transform(online_shoppers_intention_data['Month']) # e.g., 'Feb'->0, 'Mar'->1\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 4: Display the data",
   "id": "abd1804c1012a75f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = online_shoppers_intention_data.drop('Revenue', axis=1)  # all columns except target\n",
    "y = online_shoppers_intention_data['Revenue']               # target variable\n",
    "\n",
    "print(\"\\nThe data types:\")\n",
    "print(online_shoppers_intention_data.info())\n",
    "\n",
    "print(\"\\nThe summary of the numeric columns:\")\n",
    "display(online_shoppers_intention_data.describe())\n",
    "\n",
    "print(\"\\nThe whole dataset:\")\n",
    "display(online_shoppers_intention_data)\n",
    "\n",
    "print(\"The feature data (independent variables or predictors):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nTarget labels (the dependent variable or outcome):\")\n",
    "print(y.head())\n",
    "\n",
    "print(\"\\nPercentage distribution for each category in y:\")\n",
    "print(\"\\nNumber of observations per class:\")\n",
    "print(\"Frequency counts:\\n\", y.value_counts())\n",
    "print(\"\\nPercentages:\\n\", y.value_counts(normalize=True) * 100, \"%\")"
   ],
   "id": "ab7f8e832e65b7ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 5: Resample with replacement to balance the dataset",
   "id": "9a826f6e5fe4d3ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = online_shoppers_intention_data[online_shoppers_intention_data['Revenue']==0]\n",
    "df_minority = online_shoppers_intention_data[online_shoppers_intention_data['Revenue']==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority,\n",
    "                               replace=True,     # Sample with replacement\n",
    "                               n_samples=len(df_majority),    # To match the majority class\n",
    "                               random_state=53)  # To ensure the results are reproducible\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Separate features and target from balanced dataset\n",
    "X_balanced = df_balanced.drop('Revenue', axis=1)\n",
    "y_balanced = df_balanced['Revenue']\n",
    "\n",
    "print(\"\\nNumber of observations per class:\")\n",
    "print(\"Frequency counts:\\n\", y_balanced.value_counts())\n",
    "print(\"\\nPercentages:\\n\", y_balanced.value_counts(normalize=True) * 100, \"%\")\n"
   ],
   "id": "8bda3244eb59bbcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3714e5f08d77798b",
   "metadata": {},
   "source": "## Step 6: Split the data into training and testing sets"
  },
  {
   "cell_type": "code",
   "id": "dffa619fd9ed0738",
   "metadata": {},
   "source": [
    "# Split into a training set and a test set (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.30, random_state=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 7: Apply data transformation (feature scaling)",
   "id": "25ec5e541f55ba9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`StandardScaler` is a preprocessing technique from scikit-learn whose purpose is to standardize features by removing the mean and scaling it to a unit variance. It does this by applying the standardization formula to each feature:\n",
    "- Standardization formula: `z = (x - μ) / σ`\n",
    "- Where:\n",
    "   - `x` is the original value of the feature.\n",
    "   - `μ` is the mean of the feature values.\n",
    "   - `σ` is the standard deviation of the feature values.\n",
    "- The result is:\n",
    "    - The transformed data will have a mean of 0\n",
    "    - Standard deviation of 1\n",
    "    - Roughly 68% of the values will lie between -1 and 1\n",
    "    - Roughly 95% of the values will lie between -2 and 2\n",
    "\n",
    "- Advantages:\n",
    "    - Makes features comparable when they have different scales\n",
    "    - Many machine learning algorithms perform better when features are on similar scales\n",
    "    - Particularly important for algorithms that use distance calculations or assume normally distributed data\n"
   ],
   "id": "2738fdb2cb33b505"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "2797453f298ea964",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2a814bce602824e",
   "metadata": {},
   "source": "## Step 8: Train the model"
  },
  {
   "cell_type": "code",
   "id": "8eaaa43518a947e3",
   "metadata": {},
   "source": [
    "# Initialize the classifier\n",
    "model = SVC(kernel='rbf', random_state=53)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3b8feab7b12283e0",
   "metadata": {},
   "source": "## Step 9: Evaluate the Model"
  },
  {
   "cell_type": "markdown",
   "id": "7a653c7d",
   "metadata": {},
   "source": [
    "`y_pred = model.predict(X_test_scaled)`\n",
    "\n",
    "- This uses the trained decision tree classifier (`model`) to predict the labels for the test set features (`X_test`). This gives you the model’s predictions on data it has not seen before, which is necessary for evaluating its performance.\n",
    "\n",
    "`print(\"Classification Report:\\n\", classification_report(y_test, y_pred))`\n",
    "- This prints a detailed classification report comparing the true labels (`y_test`) to the predicted labels (`y_pred`). The report includes precision, recall, F1-score, and support for each class, enabling you to understand how well the model performs for each category.\n",
    "- It shows the performance metrics for a model that predicts two classes:\n",
    "    - Class 0 - A case where the user's interaction with the eCommerce website does not lead to a purchase.\n",
    "    - Class 1 - A case where the user's interaction with the eCommerce website leads to a purchase.\n",
    "\n",
    "- There are 300 total items tested:\n",
    "    - Class 0 has 3,146 (50%)\n",
    "    - Class 1 has 3,108 (50%)\n",
    "\n",
    "| Term             | Meaning                                                                                                                             |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Precision**    | Out of all items the model said are class X, how many are actually class X?                                                         |\n",
    "| **Recall**       | Out of all actual items in class X, how many did the model correctly find?                                                          |\n",
    "| **F1-score**     | A balance between precision and recall such  that a higher value means better balance.                                              |\n",
    "| **Support**      | The number of actual items in that class.                                                                                           |\n",
    "| **Macro avg**    | The average of precision, recall, and F1-score for both classes, treating them equally.                                             |\n",
    "| **Weighted avg** | The average of precision, recall, and F1-score, but weighted by how many samples are in each class (so class 1 has more influence). |\n",
    "\n",
    "- The results show that the model is much better at predicting class 1 than class 0, and overall gets 75% of predictions correct. This may be because there are more class 1 cases in the data."
   ]
  },
  {
   "cell_type": "code",
   "id": "d35f4acf0fa0c747",
   "metadata": {},
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  # Overall fraction of correct predictions\n",
    "\n",
    "# Show precision, recall, F1-score for each class\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute and display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1c3e725ee7fb758e",
   "metadata": {},
   "source": "## Step 10: Use the model to make a prediction on a new sample"
  },
  {
   "cell_type": "code",
   "id": "60626005028acb1a",
   "metadata": {},
   "source": [
    "# Create a new sample (example values based on the dataset's feature order)\n",
    "new_session = [[0,     # Administrative\n",
    "                0.0,   # Administrative_Duration\n",
    "                2,     # Informational\n",
    "                0.0,   # Informational_Duration\n",
    "                20,    # ProductRelated\n",
    "                500.0, # ProductRelated_Duration\n",
    "                0.02,  # BounceRates\n",
    "                0.01,  # ExitRates\n",
    "                0.005, # PageValues\n",
    "                0.0,   # SpecialDay\n",
    "                3,     # Month (encoded)\n",
    "                2,     # OperatingSystems\n",
    "                1,     # Browser\n",
    "                1,     # Region\n",
    "                1,     # TrafficType\n",
    "                1,     # VisitorType (Returning_Visitor encoded as 1)\n",
    "                0      # Weekend (False encoded as 0)\n",
    "               ]]\n",
    "\n",
    "# Use the same column names as the training data\n",
    "new_session_online_shoppers_intention_data = pd.DataFrame(new_session)\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = model.predict(new_session_online_shoppers_intention_data)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nPredicted Revenue:\", \"Yes\" if prediction[0] == 1 else \"No\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

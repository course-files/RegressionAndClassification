{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a069b9a",
   "metadata": {},
   "source": [
    "# Regression using the CART Algorithm (a decision tree regressor) and the Mean Squared Error Splitting Split Criterion\n",
    "| Key              | Value                                                                                                                                                                                               |\n",
    "|:-----------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Course Codes** | BBT 4106, BCM 3104, and BFS 4102                                                                                                                                                                    |\n",
    "| **Course Names** | BBT 4106: Business Intelligence I (Week 10-12 of 13),<br/>BCM 3104: Business Intelligence and Data Analytics (Week 10-12 of 13) and<br/>BFS 4102: Advanced Business Data Analytics (Week 4-6 of 13) |\n",
    "| **Semester**     | April to July 2025                                                                                                                                                                                  |\n",
    "| **Lecturer**     | Allan Omondi                                                                                                                                                                                        |\n",
    "| **Contact**      | aomondi@strathmore.edu                                                                                                                                                                              |\n",
    "| **Note**         | The lecture contains both theory and practice. This notebook forms part of the practice. This is intended for educational purpose only.                                                             |\n",
    "\n",
    "**Business context**: A restaurant called \"Siwaka Dishes\" has set a strategic objective *to optimize product profitability while maintaining customer satisfaction*. The business tracks two Key Performance Indicators (KPIs) from the financial perspective:\n",
    "\n",
    "1. **Lagging KPI**: Monthly profit\n",
    "2. **Leading KPI**: Profit per product category\n",
    "\n",
    "The business wants to leverage Machine Learning as part of AI to create a predictive model that can forecast the profit per product for future sales. This will help in:\n",
    "- Menu pricing optimization\n",
    "- Inventory management\n",
    "- Product mix decisions\n",
    "- Cost control measures\n",
    "\n",
    "The business would like the model to use the following historical data to predict the 'ProfitPerUnit'\n",
    "- `PaymentDate`\n",
    "- `CustomerType`\n",
    "- `BranchSubCounty`\n",
    "- `ProductCategoryName`\n",
    "- `QuantityOrdered`\n",
    "\n",
    "**Dataset**: The **Siwaka Dishes profit per product** dataset is a synthetic (not real) dataset that contains 17,474 payments for orders that are in either of the following states:\n",
    "- Processing\n",
    "- In Transit\n",
    "- Delivered\n",
    "\n",
    "'Pending orders' and 'Canceled' orders are excluded from the dataset. The following table presents the chosen features and the target.\n",
    "\n",
    "| **Type**                                | **Name**                  | **Description**                                                          |\n",
    "|:----------------------------------------|---------------------------|:-------------------------------------------------------------------------|\n",
    "| **Feature**                             | `PaymentDate`             | The date when the payment was made                                       |\n",
    "| <span style=\"color:red\">Excluded</span> | `OrderNumber`             | The unique Order Number that the payment was made for                    |\n",
    "| **Feature**                             | `CustomerType`            | Either a business or an individual                                       |\n",
    "| <span style=\"color:red\">Excluded</span> | `CustomerName`            | The name of the customer who made the order                              |\n",
    "| **Feature**                             | `BranchSubCounty`         | The Sub-County where the branch is located                               |\n",
    "| <span style=\"color:red\">Excluded</span> | `BranchCounty`            | The County where the branch is located                                   |\n",
    "| <span style=\"color:red\">Excluded</span> | `ProductName`             | The name of the product that was purchased                               |\n",
    "| **Feature**                             | `ProductCategoryName`     | The category in which the product was grouped in                         |\n",
    "| **Feature**                             | `QuantityOrdered`         | The number of products ordered                                           |\n",
    "| <span style=\"color:red\">Excluded</span> | `CostOfProductionPerUnit` | The cost of producing the product                                        |\n",
    "| <span style=\"color:red\">Excluded</span> | `SellingPricePerUnit`     | The price at which the product was sold to the client                    |\n",
    "| **Target**                              | `ProfitPerUnit`           | The amount of profit that the business made from the sale of the product |\n",
    "| <span style=\"color:red\">Excluded</span> | `PercentageProfitPerUnit` | The amount of profit the business made expressed as a percentage         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6f946dbe9f362",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714b5ae587a688d",
   "metadata": {},
   "source": [
    "**Purpose**: This chunk imports all the necessary libraries for data analysis, machine learning, and visualization.\n",
    "\n",
    "1. **For data manipulation - [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html):**\n",
    "    - `pandas as pd`: For loading the dataset, creating and managing DataFrames, data manipulation and analysis using DataFrames\n",
    "    - `numpy as np`: For numerical operations and array manipulations\n",
    "\n",
    "2. **For statistical data analysis - [scipy.stats](https://docs.scipy.org/doc/scipy/tutorial/stats.html)**\n",
    "    - `kurtosis`: Measures the \"tailedness\" of data distribution\n",
    "    - `skew`: Measures the asymmetry of data distribution\n",
    "\n",
    "3. **For data preprocessing and transformation - [scikit-learn.preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)**\n",
    "    - `LabelEncoder`: LabelEncoder from scikit-learn converts categorical text labels (e.g., cat, dog, mouse) into numerical values (e.g., 0, 1, 2). It is used to prepare categorical data for machine learning algorithms that require numeric inputs\n",
    "    - `StandardScaler`: For feature scaling\n",
    "\n",
    "4. **For Machine Learning - [scikit-learn](https://scikit-learn.org/stable/supervised_learning.html)**\n",
    "    - `DecisionTreeClassifier`: A class from scikit-learn that implements the CART (Classification and Regression Trees) algorithm for building decision tree models.\n",
    "    - `plot_tree`: A function from scikit-learn’s tree module that visualizes the decision tree structure.\n",
    "    - `train_test_split`: A function from scikit-learn’s model_selection module that splits the dataset into training and testing sets.\n",
    "    - `classification_report`: A function from scikit-learn’s metrics module used to evaluate the performance of the classifier. It gives detailed metrics such as precision, recall, f1-score, and support for each class.\n",
    "    - `confusion_matrix`: A function from scikit-learn’s metrics module that computes the confusion matrix to evaluate the accuracy of a classification.\n",
    "    - `GridSearchCV`: For hyperparameter tuning using cross-validation\n",
    "\n",
    "5. **For data visualization - [matplotlib](https://matplotlib.org/stable/gallery/index.html) and [seaborn](https://seaborn.pydata.org/examples/index.html)**\n",
    "    - `matplotlib.pyplot as plt`: For basic plotting functionality\n",
    "    - `seaborn as sns`: For enhanced statistical visualizations\n",
    "\n",
    "6. **For suppressing warnings - [warnings](https://docs.python.org/3/library/warnings.html)**\n",
    "    - `warnings`: Controls warning messages\n",
    "    - `warnings.filterwarnings('ignore')`: Suppresses warning messages for cleaner output\n",
    "    - Used to suppress warnings that may arise during the execution of the code. Even though it is not necessary for the code to run, it helps in keeping the output clean and focused on the results."
   ]
  },
  {
   "cell_type": "code",
   "id": "114a8659",
   "metadata": {},
   "source": [
    "# For data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For statistical data analysis\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "# For data preprocessing and transformation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For Machine Learning\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4b236e75",
   "metadata": {},
   "source": [
    "## Step 2: Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e10b6",
   "metadata": {},
   "source": [
    "**Purpose:** This chunk loads the dataset from a specified source (local file, Google Drive, or URL) into a Pandas DataFrame for further analysis.\n",
    "\n",
    "1. **URL Configuration**\n",
    "    - This specifies the location of the dataset to be loaded. You should **choose one** of the following options:\n",
    "        - **From your computer**: Uncomment the line with the local path to load the dataset from your local machine.\n",
    "        - **From your Google Drive using Google Colab**: Uncomment the lines to mount your Google Drive and specify the path to the dataset in your Google Drive.\n",
    "        - **From a URL on GitHub**: This is the default choice. Uncomment the line with the URL to load the dataset directly from a GitHub repository.\n",
    "\n",
    "2. **Data Loading Parameters**\n",
    "    - Uses `pd.read_csv()` with specific parameters:\n",
    "        - `usecols`: Loads only the columns specified in `use_cols` for memory efficiency\n",
    "        - `encoding='utf-8'`: Handles special characters in the dataset. This is suitable for most languages and special characters like ñ, €, ®. Other alternative encodings include:\n",
    "        - `encoding='utf-16'`: Supports multilingual characters, uses 2 Bytes per character.\n",
    "        - `encoding='utf-32'`: Like utf-16 but uses 4 Bytes per character, suitable for full Unicode range.\n",
    "        - `encoding='latin-1'`: Handles Western European characters (ISO-8859-1), such as ñ, ß, € without throwing decode errors.\n",
    "        - `encoding='big5'`: Traditional Chinese encoding used in Taiwan and Hong Kong.\n",
    "        - `encoding='shift_jis'`: Japanese character encoding used on Windows.\n",
    "        - You can try different encodings if you encounter the `UnicodeDecodeError` while reading a file. This is useful in cases where the business has branches across different countries and the dataset contains characters from multiple languages.\n",
    "        - `nrows=200000`: Limits the number of rows loaded to 200,000. This can be reduced or increased based on the available memory and the size of the dataset.\n",
    "    - The data is then stored in a `Pandas` DataFrame for further analysis\n",
    "    - This selective loading approach helps manage memory usage and focuses the analysis on the relevant features for the design of the model."
   ]
  },
  {
   "cell_type": "code",
   "id": "b0c2cd3b7738ced4",
   "metadata": {},
   "source": [
    "# Option 1: From your computer\n",
    "# Uncomment the following line to load the data from your computer.\n",
    "# url = './data/siwaka_dishes_view_profit_per_product.csv'\n",
    "\n",
    "# Option 2: From your Google Drive using Google Colab:\n",
    "# Uncomment the following lines to mount your Google Drive and load the data using Google Colab.\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# url = '/content/drive/My Drive/Colab Notebooks/data/siwaka_dishes_view_profit_per_product.csv'\n",
    "\n",
    "# Option 3: From a URL on GitHub\n",
    "# Uncomment the following line to load the data from a URL on GitHub.\n",
    "url = 'https://github.com/course-files/RegressionAndClassification/raw/refs/heads/main/data/siwaka_dishes_view_profit_per_product.csv'\n",
    "\n",
    "use_cols = ['PaymentDate', 'OrderNumber', 'CustomerType', 'CustomerName', 'BranchSubCounty', 'BranchCounty', 'ProductName', 'ProductCategoryName', 'QuantityOrdered', 'CostOfProductionPerUnit', 'SellingPricePerUnit', 'ProfitPerUnit', 'PercentageProfitPerUnit']\n",
    "profit_per_product = pd.read_csv(url, usecols=use_cols, encoding='utf-8', nrows=200000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dd0dab7dbd81d6b9",
   "metadata": {},
   "source": [
    "### Assign correct data types to the columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ffe58eeaeb85342",
   "metadata": {},
   "source": [
    "# Convert PaymentDate column to a datetime data type\n",
    "profit_per_product['PaymentDate'] = pd.to_datetime(profit_per_product['PaymentDate'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8f85de416cc97e97",
   "metadata": {},
   "source": [
    "## Step 3: Initial Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "id": "b8e32009938a3a5b",
   "metadata": {},
   "source": [
    "print(\"\\n*1* The number of observations and variables\")\n",
    "display(profit_per_product.shape)\n",
    "\n",
    "print(\"\\n*2* The data types:\")\n",
    "display(profit_per_product.info())\n",
    "\n",
    "print(\"\\n*3* The summary of the numeric columns:\")\n",
    "display(profit_per_product.describe())\n",
    "\n",
    "print(\"\\n*4* The whole dataset:\")\n",
    "display(profit_per_product)\n",
    "\n",
    "print(\"\\n*5* The first 5 rows in the dataset:\")\n",
    "display(profit_per_product.head())\n",
    "\n",
    "print(\"\\n*6* Percentage distribution for each category\")\n",
    "print(\"\\nNumber of observations per class:\")\n",
    "print(\"Frequency counts:\\n\", profit_per_product['BranchCounty'].value_counts())\n",
    "print(\"\\nPercentages:\\n\", profit_per_product['BranchCounty'].value_counts(normalize=True) * 100, \"%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c6b2b387a3bce6e1",
   "metadata": {},
   "source": [
    "### Measures of Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd0ac8ac4013b2",
   "metadata": {},
   "source": [
    "#### Variance of numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57605d99e707202f",
   "metadata": {},
   "source": [
    "**Selection of numeric columns**\n",
    "- The code selects columns with numeric data types (`int64` and `float64`) that can be subjected to mathematical or statistical functions.\n",
    "- This is done using `select_dtypes()` method of the DataFrame, which filters columns based on their data types."
   ]
  },
  {
   "cell_type": "code",
   "id": "580a6b9f7de7951",
   "metadata": {},
   "source": [
    "numeric_cols = profit_per_product.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(\"\\nVariance of the numeric columns:\")\n",
    "print(profit_per_product[numeric_cols].var())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9482bfa7cbc68d4f",
   "metadata": {},
   "source": [
    "#### Standard deviation of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "39059eade3ac334",
   "metadata": {},
   "source": [
    "print(\"\\nStandard deviation of the numeric columns:\")\n",
    "print(profit_per_product[numeric_cols].std())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7141593efc9b1fa8",
   "metadata": {},
   "source": [
    "#### Kurtosis of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "32fcead86f711a29",
   "metadata": {},
   "source": [
    "print(\"\\nFisher Kurtosis of numeric columns:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive kurtosis indicates heavier tails (more outliers) than what is expected in a normal distribution - leptokurtic\")\n",
    "print(\"→ Negative kurtosis indicates lighter tails (less outliers) than what is expected in a normal distribution - platykurtic\")\n",
    "print(\"→ A normal distribution has kurtosis of 0 - mesokurtic\")\n",
    "print(\"\\nKurtosis values:\")\n",
    "print(profit_per_product[numeric_cols].apply(lambda x: kurtosis(x, fisher=True)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "49e19da391fe678c",
   "metadata": {},
   "source": [
    "#### Skewness of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "6b3bbff4ac604e02",
   "metadata": {},
   "source": [
    "print(\"\\nSkewness of numeric columns:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive skewness indicates a long right tail (right-skewed distribution)\")\n",
    "print(\"→ Negative skewness indicates a long left tail (left-skewed distribution)\")\n",
    "print(\"→ Skewness close to 0 indicates a symmetric distribution\")\n",
    "print(\"\\nSkewness values:\")\n",
    "print(profit_per_product[numeric_cols].apply(lambda x: skew(x)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "13732dd51824950f",
   "metadata": {},
   "source": [
    "### Measures of Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f17b1b75f9b56",
   "metadata": {},
   "source": [
    "#### Covariance matrix of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e6ede379b12fbb0",
   "metadata": {},
   "source": [
    "print(\"\\nCovariance matrix of numeric features:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive values indicate that variables move in the same direction\")\n",
    "print(\"→ Negative values indicate that variables move in opposite directions\")\n",
    "print(\"→ Values close to 0 indicate little to no linear relationship\")\n",
    "print(\"\\nCovariance values:\")\n",
    "display(profit_per_product[numeric_cols].cov())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc4d1d02b9e134d0",
   "metadata": {},
   "source": [
    "#### Correlation matrix of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e7ecf7a73010c9b",
   "metadata": {},
   "source": [
    "print(\"\\nSpearman's rank correlation matrix of numeric features:\")\n",
    "spearman_corr = profit_per_product[numeric_cols].corr(method='spearman')\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Values range from -1 to +1\")\n",
    "print(\"→ +1 indicates perfect positive correlation\")\n",
    "print(\"→ -1 indicates perfect negative correlation\")\n",
    "print(\"→ 0 indicates no correlation\")\n",
    "print(\"\\nCorrelation values:\")\n",
    "display(spearman_corr)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af2a619d610e2d23",
   "metadata": {},
   "source": [
    "### Basic visualization of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64e3240de1cac02",
   "metadata": {},
   "source": [
    "- `n_cols = 3` Sets the number of plots per row to 3\n",
    "- `n_rows = (len(numeric_cols) // n_cols) + (1 if len(numeric_cols) % n_cols else 0)` Calculates the number of rows needed based on the number of numeric columns and the number of columns per row.\n",
    "- `plt.figure(figsize=(12, 5 * n_rows))` Sets the figure size to be wider and taller based on the number of rows.\n",
    "- `for i, col in enumerate(numeric_cols, 1):` Iterates over each numeric column (`numeric_cols`), starting the index at 1. `enumerate(numeric_cols, 1)` returns pairs of (index, value) for each item in the list. The 1 means that the index will start from 1, e.g., (1, 'Days for shipping (real)'), (2, 'Days for shipment (scheduled)'), etc.\n",
    "- `plt.subplot(n_rows, n_cols, i)` Creates a subplot in a grid layout with `n_rows` rows and `n_cols` columns, placing the current plot in the `i`-th position.\n",
    "- `sns.histplot(data=profit_per_product, x=col)` Plots a histogram for the current numeric column using Seaborn's `histplot` function.\n",
    "- `sns.boxplot(data=profit_per_product, y=col)` Plots a box plot for the current numeric column using Seaborn's `boxplot` function.\n",
    "- `sns.despine(right=True, top=True)` Removes the right and top spines (borders) of the plot for a cleaner look.\n",
    "- `plt.title(f'Distribution of {col}')` Sets the title of the current subplot to indicate which column's distribution is being shown.\n",
    "- `plt.grid(axis='y', alpha=0.2)` Adds a grid to the y-axis with a transparency level of 0.2 for better visibility.\n",
    "- `plt.grid(axis='x', visible=False)` Hides the grid for the x-axis to reduce clutter and increase the data-to-ink ratio.\n",
    "- `plt.tight_layout()` Adjusts the spacing between subplots to prevent overlap and ensure a clean layout.\n",
    "- `plt.show()` Displays the entire figure with all subplots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ecb705130b48",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "id": "5f6bd9475926f361",
   "metadata": {},
   "source": [
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) // n_cols) + (1 if len(numeric_cols) % n_cols else 0)\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.histplot(data=profit_per_product, x=col)\n",
    "    sns.despine(right=True, top=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.grid(axis='y', alpha=0.2)\n",
    "    plt.grid(axis='x', visible=False)\n",
    "plt.tight_layout()  # Adjust spacing\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "789dc6d42d812f57",
   "metadata": {},
   "source": [
    "#### Box plots"
   ]
  },
  {
   "cell_type": "code",
   "id": "7d16da1601ddabf7",
   "metadata": {},
   "source": [
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) // n_cols) + (1 if len(numeric_cols) % n_cols else 0)\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.boxplot(data=profit_per_product, y=col)\n",
    "    sns.despine(right=True, top=True, bottom=True)\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "    plt.grid(axis='y', alpha=0.2)\n",
    "    plt.grid(axis='x', visible=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59abafcf5eab4f40",
   "metadata": {},
   "source": [
    "#### Missing data plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea8706303254079",
   "metadata": {},
   "source": [
    "- This visualization helps to quickly identify which columns have missing values and the extent of the missing data. The heatmap will show yellow for missing values and purple for present values, making it easy to spot patterns of missingness. This is useful for understanding the completeness of the dataset and deciding how to handle missing values in subsequent analysis.\n",
    "- The code uses `Seaborn`'s `heatmap()` function to visualize missing data in the DataFrame.\n",
    "- The code also uses the `isnull()` method to create a boolean DataFrame indicating where values are missing (True) or present (False).\n",
    "- `yticklabels=False` hides the y-axis labels to reduce clutter and increase the data-to-ink ratio.\n",
    "- `cbar=False` removes the color bar, which is not necessary for this plot.\n",
    "- `cmap='viridis'` sets the color map to 'viridis' which is a perceptually uniform color map suitable for visualizing missing data; yellow represents missing values, while purple represents present values.\n",
    "- `plt.title('Missing Data')` sets the title of the plot to 'Missing Data'\n",
    "- `plt.show()` displays the plot."
   ]
  },
  {
   "cell_type": "code",
   "id": "201cbff78759d23c",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(profit_per_product.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "plt.title('Missing Data')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7232ddefcd74df8c",
   "metadata": {},
   "source": [
    "#### Correlation heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b0a8d12f5fc0c",
   "metadata": {},
   "source": [
    "- This visualization helps to quickly identify relationships between numeric features. The heatmap will show the strength and direction of correlations, with colors indicating positive (red) or negative (blue) correlations. This is useful for understanding how features relate to each other and can inform feature selection or feature engineering in subsequent analysis.\n",
    "- The code uses `Searborn`'s `heatmap()` function to visualize the Spearman correlation matrix of the numeric features in the DataFrame.\n",
    "- `annot=True` adds the correlation values as annotations on the heatmap.\n",
    "- `cmap='coolwarm'` sets the color map to 'coolwarm' which provides a gradient from blue (negative correlation) to red (positive correlation).\n",
    "- `center=0` centers the color map at 0, which is useful for visualizing both positive and negative correlations."
   ]
  },
  {
   "cell_type": "code",
   "id": "4b4d94ec740985b2",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8c7dc76de206f039",
   "metadata": {},
   "source": [
    "#### Scatter plot matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647417c892b7132",
   "metadata": {},
   "source": [
    "- This visualization helps to quickly identify relationships between pairs of numeric features. The scatter plot matrix will show scatter plots for each pair of numeric features, allowing for visual inspection of relationships, trends, and potential outliers. This is useful for understanding how features interact with each other and can inform feature selection or feature engineering in subsequent analysis.\n",
    "- The code uses `Seaborn`'s `pairplot()` function to create a scatter plot matrix of the numeric features in the DataFrame\n",
    "- `plt.suptitle('Scatter Plot Matrix', y=1.02)` Adds a centered title above all subplots (or the single plot). `y=1.02` Moves the title upward by 2% of the figure height (default is y=1.0). This is done to prevent overlap in the subplot titles."
   ]
  },
  {
   "cell_type": "code",
   "id": "19fcfbe57098ce4b",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.pairplot(profit_per_product[numeric_cols])\n",
    "plt.suptitle('Scatter Plot Matrix', y=1.02)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc020a600afd971e",
   "metadata": {},
   "source": [
    "## Step 4: Data preprocessing and transformation\n",
    "\n",
    "- Decision trees can handle features that are in different units (e.g., age [0 - 100] vs. income [0 - 1,000,000]), therefore, there is no need to perform data transformations such as standardization (setting the mean = 0 and standard deviation = 1) using `StandardScaler()` or normalization (setting the minimum value = 0 and the maximum value = 1) using `MinMaxScaler()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b685b47d1c7ea2",
   "metadata": {},
   "source": "### Identify the non-numeric columns"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Purpose:** Identifies non-numeric columns (e.g., strings/objects) by excluding numeric (int64, float64) and datetime data types.\n",
    "\n",
    "**Output:** List of non-numeric column names."
   ],
   "id": "c6eea048d653b0a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categorical_cols = profit_per_product.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]']).columns\n",
    "\n",
    "print(\"\\nThe identified categorical columns are:\")\n",
    "print(categorical_cols)"
   ],
   "id": "3af222bc7acab4a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Represent the non-numeric, categorical columns as numeric using label encoding",
   "id": "80c2345eb005789a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `profit_per_product_encoded = profit_per_product.copy()`: Preserves original data integrity while creating a modified version for encoding.\n",
    "- `label_encoders = {}`: Creates a dictionary to store the label encoder that was used for each column\n",
    "\n",
    "- `for col in categorical_cols:` For each categorical column:\n",
    "    - `label_encoders[col] = LabelEncoder()`: Creates a LabelEncoder instance\n",
    "    - `profit_per_product_encoded[col] = label_encoders[col].fit_transform(profit_per_product[col])`: Replaces text values with numeric codes (e.g., \"Electronics\" → 0, \"Furniture\" → 1)\n",
    "\n",
    "- `profit_per_product_encoded.head()` and `profit_per_product_encoded.info()`: Used to confirm that the non-numeric columns are now numeric"
   ],
   "id": "4d04aec6e1775b52"
  },
  {
   "cell_type": "code",
   "id": "ad6904dedf8f7159",
   "metadata": {},
   "source": [
    "profit_per_product_encoded = profit_per_product.copy()\n",
    "\n",
    "# Create a dictionary to store the label encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode all categorical columns\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    profit_per_product_encoded[col] = label_encoders[col].fit_transform(profit_per_product[col])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da10d154288f3877",
   "metadata": {},
   "source": [
    "profit_per_product_encoded.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed15628609a854ff",
   "metadata": {},
   "source": [
    "profit_per_product_encoded.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Feature engineering",
   "id": "e289d19848a5a582"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Decision tree models (both classifiers and regressors) expect numeric data.\n",
    "- The `datetime64` must be converted to a numeric data type such as `int64`. This is done for each section of the date so that the numeric values are made up of `year`, `month`, `day`, and `dayofweek`.\n",
    "- Although `datetime64` data types are not directly usable by decision trees, **feature engineering** can be performed by extracting relevant temporal components such as\n",
    "   - year\n",
    "   - month\n",
    "   - day\n",
    "   - dayofweek\n",
    "   - hour, minute, second (if relevant)\n",
    "   - Elapsed time (e.g., timestamp converted to int64)\n",
    "\n",
    "- These extracted features are numerical and can then be used as input to the model."
   ],
   "id": "27fb7262ac4837df"
  },
  {
   "cell_type": "code",
   "id": "74995cc61233be3d",
   "metadata": {},
   "source": [
    "# First, identify datetime columns\n",
    "datetime_columns = profit_per_product_encoded.select_dtypes(include=['datetime64']).columns\n",
    "\n",
    "# Convert datetime to numeric features\n",
    "for col in datetime_columns:\n",
    "    profit_per_product_encoded[f'{col}_year'] = profit_per_product_encoded[col].dt.year\n",
    "    profit_per_product_encoded[f'{col}_month'] = profit_per_product_encoded[col].dt.month\n",
    "    profit_per_product_encoded[f'{col}_day'] = profit_per_product_encoded[col].dt.day\n",
    "    profit_per_product_encoded[f'{col}_dayofweek'] = profit_per_product_encoded[col].dt.dayofweek\n",
    "\n",
    "# Drop original datetime columns\n",
    "profit_per_product_encoded = profit_per_product_encoded.drop(columns=datetime_columns)\n",
    "\n",
    "# Confirm the feature engineering\n",
    "profit_per_product_encoded.head(15)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create X and y datasets for the features and target variable respectively",
   "id": "ea3932ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`X = ...`\n",
    "* Separates the data such that the data frame called `X` contains only the features (independent variables or predictors)\n",
    "\n",
    "`y = ...`\n",
    "* Separates the data such that the data frame called `y` contains only the target (dependent variable or outcome)"
   ],
   "id": "5dd7e8a810ad20ea"
  },
  {
   "cell_type": "code",
   "id": "b0e94844d5b7513d",
   "metadata": {},
   "source": [
    "X = profit_per_product_encoded.drop(['OrderNumber', 'CustomerName',\n",
    "                                     'BranchCounty', 'ProductName', 'CostOfProductionPerUnit',\n",
    "                                     'SellingPricePerUnit', 'ProfitPerUnit',\n",
    "                                     'PercentageProfitPerUnit'], axis=1)\n",
    "y = profit_per_product_encoded['ProfitPerUnit']\n",
    "\n",
    "print(\"\\nThe number of observations and variables in the features dataset\")\n",
    "print(X.shape)\n",
    "print(\"\\nThe columns in the features dataset\")\n",
    "print(X.columns)\n",
    "\n",
    "print(\"\\nThe number of observations and variables in the target dataset\")\n",
    "print(y.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ce063589a98b71e",
   "metadata": {},
   "source": [
    "### Train‑test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124c1f3bd91b0c0",
   "metadata": {},
   "source": [
    "- `train_test_split` is a function from scikit-learn that splits your dataset into two parts: one for training the model and one for testing it.\n",
    "- `X` is your feature data (inputs), and `y` is your target data (outputs/labels).\n",
    "- `test_size=0.3` means 30% of the data in both `X` and `y` will be used for testing, and the remaining 70% in both `X` and `y` for training.\n",
    "- `random_state=53` sets a seed for the random number generator, ensuring that the split is reproducible (you get the same split every time you run the code).\n",
    "\n",
    "- The `train_test_split` function returns four objects:\n",
    "  - `X_train`: features for training\n",
    "  - `X_test`: features for testing\n",
    "  - `y_train`: labels for training\n",
    "  - `y_test`: labels for testing\n",
    "\n",
    "**Why:**\n",
    "Splitting the data this way allows you to train your model on one part of the data and evaluate its performance on unseen data, which helps prevent overfitting and gives an objective measure of the model's accuracy.\n",
    "\n",
    "*Analogy:* This is similar to how a student learning a subject is not exposed to only one past paper that they can memorize. If they memorize the past paper and the exam assesses them on a different set of questions, then their performance in the exam will not be the same as their performance in the memorized past paper."
   ]
  },
  {
   "cell_type": "code",
   "id": "11b4c772ea47b91c",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=53)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6f17070b",
   "metadata": {},
   "source": " ## Step 5: Design a baseline decision tree model"
  },
  {
   "cell_type": "markdown",
   "id": "36a9c7ba1b5d224d",
   "metadata": {},
   "source": [
    "- This step creates a baseline decision tree regressor model using the `DecisionTreeRegressor` class from scikit-learn.\n",
    "- The algorithm uses the training data (`X_train` and `y_train`) to learn the mapping between the features and the target variable. This mapping is what is represented as the **model**.\n",
    "- The model is then used to make predictions on the test data (`X_test`).\n",
    "- The performance of the model is evaluated using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R-squared (R²).\n",
    "- MAE measures the average absolute difference between predicted and actual values. MAE represents the average size of the prediction error. It gives a sense of how much, on average, predictions deviate from actual values\n",
    "- MSE measures the average squared difference between predicted and actual values.\n",
    "- RMSE is the square root of MSE, providing an error metric in the same units as the target variable.\n",
    "- R² indicates the proportion of variance in the target variable that is explained by the model, with values closer to 1 indicating a better fit.\n",
    "\n",
    "---\n",
    "- **R²** (also called the **coefficient of determination**), measures how well the model explains the variance in the target variable.\n",
    "- It ranges typically from 0 to 1, where:\n",
    "  - R² = 1: Perfect prediction\n",
    "  - R² = 0: The model's predictions are similar to predicting the mean (similar to guessing)\n",
    "  - R²<0: The model's predictions are worse than predicting the mean (worse than guessing)"
   ]
  },
  {
   "cell_type": "code",
   "id": "5d2ecc0e",
   "metadata": {},
   "source": [
    "decisiontree_baseline_model = DecisionTreeRegressor(random_state=53)\n",
    "decisiontree_baseline_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decisiontree_baseline_model.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "mse  = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print('The baseline decision tree model\\'s performance metrics:\\n')\n",
    "print(f'MAE : {mae:,.2f}')\n",
    "print(f'MSE : {mse:,.2f}')\n",
    "print(f'RMSE: {rmse:,.2f}')\n",
    "print(f'R²  : {r2:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ea587744",
   "metadata": {},
   "source": [
    "## Step 6: Perform hyperparameter tuning"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **Hyperparameter tuning** focuses on hyperparameters which are external configurations of a model that cannot be learned from the data and must be set before training.\n",
    "- Examples of hyperparameters include the maximum depth of a decision tree, the minimum number of samples in the leaf node of a decision tree, “k” in kNN, and “k” in k Means Clustering, etc.\n",
    "- Parameter tuning focuses on parameters which are internal to the model and are learned from the data, e.g., coefficients in linear regression or logistic regression and weights in neural networks\n",
    "- The `GridSearchCV` function in Python (from the `sklearn.model_selection` module) is used to systematically search for the best combination of hyperparameters for a given machine learning model, by performing cross-validation.\n",
    "  - `param_grid`: This is a dictionary that defines the **grid** of hyperparameters to search. For example, different values for `max_depth`, `min_samples_split`, etc.\n",
    "  - `cv=5`: This applies 5-fold cross-validation such that the data is split into 5 subsets. Each subset gets a turn as a validation set while the others are used for training.\n",
    "  - `n_jobs`: Tells the grid search to use all available CPU cores to parallelize the computation. Thus speeding up the search.\n",
    "  - `verbose=1`: Displays progress messages during the search. Helps track the process while running."
   ],
   "id": "7673e24d5d49d558",
   "attachments": {
    "24b920b3-b176-4664-9c20-e9c75e5f9c7d.png": {
     "image/png": "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"
    }
   }
  },
  {
   "cell_type": "code",
   "id": "4296ebca",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['squared_error', 'friedman_mse']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    decisiontree_baseline_model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters after hyperparameter tuning:', grid.best_params_)\n",
    "decisiontree_best_model = grid.best_estimator_\n",
    "\n",
    "y_pred_best = decisiontree_best_model.predict(X_test)\n",
    "mae_best  = mean_absolute_error(y_test, y_pred_best)\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2_best   = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f'Optimised MAE : {mae_best:,.2f}')\n",
    "print(f'Optimised MSE: {rmse_best:,.2f}')\n",
    "print(f'Optimised RMSE: {rmse_best:,.2f}')\n",
    "print(f'Optimised R²  : {r2_best:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b8a80a8",
   "metadata": {},
   "source": [
    "## Step 7: Display the feature importance"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `importances = pd.Series(decisiontree_best_model.feature_importances_, index=X.columns)`\n",
    "    - Creates a pandas Series containing feature importance scores\n",
    "    - `feature_importances_` is an attribute of the trained decision tree model that shows how much each feature contributed to predictions\n",
    "    - `index=X.columns` labels each importance score with its corresponding feature name\n",
    "\n",
    "- `top_importances = importances.sort_values(ascending=False).head(10)`\n",
    "    - Sorts the importance scores in descending order (most important first)\n",
    "    - `.head(10)` selects only the top 10 most important features\n",
    "\n",
    "- `top_importances.plot(kind='barh')`\n",
    "    - Creates a horizontal bar chart (`'barh'`) of the feature importances\n"
   ],
   "id": "d610423e3fcd8cd6"
  },
  {
   "cell_type": "code",
   "id": "f95099c9",
   "metadata": {},
   "source": [
    "important_features = pd.Series(decisiontree_best_model.feature_importances_, index=X.columns)\n",
    "top10_important_features = important_features.sort_values(ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "top10_important_features.plot(kind='barh')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 10 Most Important Features')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.grid(axis='x', alpha=0.2)\n",
    "plt.grid(axis='y', visible=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14f98129",
   "metadata": {},
   "source": "## Step 8: Visualize the decision tree"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Visualising the entire tree can be difficult when it is deep. For illustrative purposes, we can restrict it to a shallower depth using `max_depth=3`.\n",
    "\n",
    "`plt.figure(figsize=(15, 10))`\n",
    "- This creates a new matplotlib figure with a size of 12 inches by 8 inches to ensure that the decision tree plot is large and readable.\n",
    "\n",
    "plot_tree(decisiontree_best_model,\n",
    "          feature_names=profit_per_product_encoded.columns,\n",
    "          max_depth=3,\n",
    "          filled=True,\n",
    "          fontsize=8)\n",
    "\n",
    "`plot_tree(...)`\n",
    "- Plots the trained decision tree (`decisiontree_best_model`).\n",
    "    - `feature_names=profit_per_product_encoded.columns`: Labels the tree’s nodes with the feature names.\n",
    "    - `filled=True`: Colors the nodes based on the class for better visualization.\n",
    "    - `fontsize=8`: Sets the font size for the text in the plot to 8 for better readability.\n",
    "    - `max_depth=3`: Limits the depth of the tree to 3 levels for better readability.\n",
    "- This visually shows how the decision tree splits the data and makes decisions.\n",
    "\n",
    "`plt.title(\"Decision Tree using the Mean Squared Error (MSE) Splitting Criterion\")`\n",
    "- Sets the title of the plot to provide context for the visualization.\n",
    "\n",
    "`plt.show()`\n",
    "- This is used to display the plot in the notebook."
   ],
   "id": "eb3897af5664d364"
  },
  {
   "cell_type": "code",
   "id": "73cdb9a0",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(decisiontree_best_model,\n",
    "          feature_names=profit_per_product_encoded.columns,\n",
    "          filled=True,\n",
    "          fontsize=8,\n",
    "          max_depth=3)\n",
    "plt.title(\"Decision Tree using the Mean Squared Error (MSE) Splitting Criterion\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c23a76cdee34ccf4",
   "metadata": {},
   "source": [
    "## Step 9: Make predictions on new data and save the results for reporting in Power BI"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e269ba789a150cf",
   "metadata": {},
   "source": [
    "# Create a DataFrame with new customer data (replace values as needed)\n",
    "new_data = pd.DataFrame({\n",
    "    'PaymentDate': ['11-07-25', '15-08-25'],\n",
    "    'CustomerType': ['Business', 'Individual'],\n",
    "    'BranchSubCounty': ['Kilimani', 'Langata'],\n",
    "    'ProductCategoryName': ['Meat-Based Dishes', 'Fried Dishes'],\n",
    "    'QuantityOrdered': [8, 4]\n",
    "})\n",
    "\n",
    "# Convert PaymentDate column to datetime\n",
    "new_data['PaymentDate'] = pd.to_datetime(new_data['PaymentDate'])\n",
    "\n",
    "# Identify all datetime columns\n",
    "datetime_columns = new_data.select_dtypes(include=['datetime64']).columns\n",
    "\n",
    "# Convert datetime to numeric features\n",
    "for col in datetime_columns:\n",
    "    new_data[f'{col}_year'] = new_data[col].dt.year\n",
    "    new_data[f'{col}_month'] = new_data[col].dt.month\n",
    "    new_data[f'{col}_day'] = new_data[col].dt.day\n",
    "    new_data[f'{col}_dayofweek'] = new_data[col].dt.dayofweek\n",
    "\n",
    "# Drop original datetime columns\n",
    "new_data = new_data.drop(columns=datetime_columns)\n",
    "\n",
    "# Create a copy of the data for encoding\n",
    "new_data_encoded = new_data.copy()\n",
    "\n",
    "# Use transform() instead of fit_transform() since the encoder is already fitted\n",
    "# Only transform new data using the fitted encoders\n",
    "for col in categorical_cols:\n",
    "    if col in new_data.columns:\n",
    "        new_data_encoded[col] = label_encoders[col].transform(new_data[col])\n",
    "\n",
    "# Make predictions\n",
    "predictions = decisiontree_best_model.predict(new_data_encoded)\n",
    "\n",
    "# Add predictions as a new column\n",
    "new_data_encoded['Predicted_Order_Profit'] = predictions\n",
    "\n",
    "display(new_data_encoded)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2358ad84ea36f25e",
   "metadata": {},
   "source": [
    "# Load new data from the URL\n",
    "url = 'https://github.com/course-files/RegressionAndClassification/raw/refs/heads/main/data/siwaka_dishes_view_profit_per_product_new_data.csv'\n",
    "\n",
    "new_data_all_cols = pd.read_csv(url, encoding='utf-8', nrows=200000)\n",
    "new_data = pd.read_csv(url, usecols=use_cols, encoding='utf-8', nrows=200000)\n",
    "\n",
    "# Create a copy for encoding\n",
    "new_data_encoded = new_data.copy()\n",
    "\n",
    "new_data_encoded = new_data_encoded.drop(['OrderNumber', 'CustomerName',\n",
    "                                     'BranchCounty', 'ProductName', 'CostOfProductionPerUnit',\n",
    "                                     'SellingPricePerUnit', 'ProfitPerUnit',\n",
    "                                     'PercentageProfitPerUnit'], axis=1)\n",
    "\n",
    "# Convert PaymentDate column to datetime\n",
    "new_data_encoded['PaymentDate'] = pd.to_datetime(new_data_encoded['PaymentDate'])\n",
    "\n",
    "# Identify all datetime columns\n",
    "datetime_columns = new_data_encoded.select_dtypes(include=['datetime64']).columns\n",
    "\n",
    "# Convert datetime to numeric features\n",
    "for col in datetime_columns:\n",
    "    new_data_encoded[f'{col}_year'] = new_data_encoded[col].dt.year\n",
    "    new_data_encoded[f'{col}_month'] = new_data_encoded[col].dt.month\n",
    "    new_data_encoded[f'{col}_day'] = new_data_encoded[col].dt.day\n",
    "    new_data_encoded[f'{col}_dayofweek'] = new_data_encoded[col].dt.dayofweek\n",
    "\n",
    "# Drop original datetime columns\n",
    "new_data_encoded = new_data_encoded.drop(columns=datetime_columns)\n",
    "\n",
    "# Get a list of categorical columns (those not in numeric_cols)\n",
    "categorical_cols = new_data_encoded.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]']).columns\n",
    "\n",
    "# Apply encoding to categorical columns using the fitted label encoders\n",
    "for col in categorical_cols:\n",
    "    if col in new_data.columns:\n",
    "        new_data_encoded[col] = label_encoders[col].transform(new_data_encoded[col])\n",
    "\n",
    "# Make predictions\n",
    "predictions = decisiontree_best_model.predict(new_data_encoded)\n",
    "\n",
    "# Add predictions to the original (non-encoded) data\n",
    "new_data_all_cols['Predicted_Order_Profit'] = predictions\n",
    "\n",
    "# Save the results to a CSV file\n",
    "# Option 1: Save to your computer\n",
    "# Uncomment the following line to save the file to your computer.\n",
    "# output_file = './data/siwaka_dishes_view_profit_per_product_predicted_data.csv'\n",
    "\n",
    "# Option 2: Save to your Google Drive using Google Colab:\n",
    "# Uncomment the following lines to mount your Google Drive and save the data using Google Colab.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "output_file = '/content/drive/My Drive/Colab Notebooks/data/siwaka_dishes_view_profit_per_product_predicted_data.csv'\n",
    "\n",
    "# Save the results to a CSV file in the specified data folder\n",
    "new_data_all_cols.to_csv(output_file, index=False)\n",
    "\n",
    "# Display the first few rows of the results\n",
    "print(\"First few rows of the data with predictions:\")\n",
    "display(new_data_all_cols.head(20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "614efbb2",
   "metadata": {},
   "source": [
    "## Business Insights\n",
    "- A decision tree regressor can model non‑linear relationships without the need for extensive feature engineering.\n",
    "- However, hyper‑parameter tuning and careful pruning are essential to avoid overfitting.\n",
    "- Forecasting the profit per product for future sales can help in:\n",
    "    - Menu pricing optimization: set prices that maximize revenue while remaining competitive and profitable.\n",
    "    - Product mix decisions: informs which high-profit products to promote or retain based on forecasted profitability trends.\n",
    "    - Cost control measures: highlights profit margins and helps identify areas where costs can be reduced without compromising product quality."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

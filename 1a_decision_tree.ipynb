{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98779557a508068a",
   "metadata": {},
   "source": [
    "# Classification using the CART Algorithm (a decision tree classifier) and the Gini Impurity Split Criterion\n",
    "\n",
    "| Key              | Value                                                                                                                                                                                               |\n",
    "|:-----------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Course Codes** | BBT 4106, BCM 3104, and BFS 4102                                                                                                                                                                    |\n",
    "| **Course Names** | BBT 4106: Business Intelligence I (Week 10-12 of 13),<br/>BCM 3104: Business Intelligence and Data Analytics (Week 10-12 of 13) and<br/>BFS 4102: Advanced Business Data Analytics (Week 4-6 of 13) |\n",
    "| **Semester**     | April to July 2025                                                                                                                                                                                  |\n",
    "| **Lecturer**     | Allan Omondi                                                                                                                                                                                        |\n",
    "| **Contact**      | aomondi@strathmore.edu                                                                                                                                                                              |\n",
    "| **Note**         | The lecture contains both theory and practice. This notebook forms part of the practice. This is intended for educational purpose only.                                                             |\n",
    "\n",
    "**Business context**: A business has a strategic objective to *reduce customer churn to 10% by the end of the current financial year*. The lagging KPI in the customer perspective of the business' performance is the churn rate whereas its leading KPI is the number of support calls. The business would like to predict whether a customer will renew their subscription so that the marketing and sales teams can intervene early and avoid losing customers.\n",
    "\n",
    "**Dataset**: The synthetic (not real) dataset used in this notebook is based on the **\"Subscription Churn\"** dataset. It contains 1,000 observations of customer data with the following features and target.\n",
    "\n",
    "| **Type**    | **Name**        | **Description**                                                                                       |\n",
    "|:------------|-----------------|:------------------------------------------------------------------------------------------------------|\n",
    "| **Feature** | `monthly_fee`   | Monthly fee paid by the customer                                                                      |\n",
    "| **Feature** | `customer_age`  | Age of the customer in years                                                                          |\n",
    "| **Feature** | `support_calls` | Number of support calls made by the customer                                                          |\n",
    "| **Target**  | `renew`         | A categorical variable that indicates if the customer renewed (1) or cancelled (0) their subscription |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f4645b58c95cc",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b5b4f",
   "metadata": {},
   "source": [
    "**Purpose**: This chunk imports all the necessary libraries for data analysis, machine learning, and visualization.\n",
    "\n",
    "1. **For data manipulation - [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html):**\n",
    "    - `pandas as pd`: For loading the dataset, creating and managing DataFrames, data manipulation and analysis using DataFrames\n",
    "\n",
    "2. **For statistical data analysis - [scipy.stats](https://docs.scipy.org/doc/scipy/tutorial/stats.html)**\n",
    "    - `kurtosis`: Measures the \"tailedness\" of data distribution\n",
    "    - `skew`: Measures the asymmetry of data distribution\n",
    "\n",
    "3. **For Machine Learning - [scikit-learn](https://scikit-learn.org/stable/supervised_learning.html)**\n",
    "    - `DecisionTreeClassifier`: A class from scikit-learn that implements the CART (Classification and Regression Trees) algorithm for building decision tree models.\n",
    "    - `plot_tree`: A function from scikit-learn’s tree module that visualizes the decision tree structure.\n",
    "    - `train_test_split`: A function from scikit-learn’s model_selection module that splits the dataset into training and testing sets.\n",
    "    - `classification_report`: A function from scikit-learn’s metrics module used to evaluate the performance of the classifier. It gives detailed metrics such as precision, recall, f1-score, and support for each class.\n",
    "    - `confusion_matrix`: A function from scikit-learn’s metrics module that computes the confusion matrix to evaluate the accuracy of a classification.\n",
    "    - `GridSearchCV`: For hyperparameter tuning using cross-validation\n",
    "\n",
    "4. **For data visualization - [matplotlib](https://matplotlib.org/stable/gallery/index.html) and [seaborn](https://seaborn.pydata.org/examples/index.html)**\n",
    "    - `matplotlib.pyplot as plt`: For basic plotting functionality\n",
    "    - `seaborn as sns`: For enhanced statistical visualizations\n",
    "\n",
    "5. **For suppressing warnings - [warnings](https://docs.python.org/3/library/warnings.html)**\n",
    "    - `warnings`: Controls warning messages\n",
    "    - `warnings.filterwarnings('ignore')`: Suppresses warning messages for cleaner output\n",
    "    - Used to suppress warnings that may arise during the execution of the code. Even though it is not necessary for the code to run, it helps in keeping the output clean and focused on the results."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "# For data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# For statistical data analysis\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "# For Machine Learning\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa681e97ffbe68a9",
   "metadata": {},
   "source": [
    "## Step 2: Load and Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eef830",
   "metadata": {},
   "source": [
    "**Purpose:** This chunk loads the dataset from a specified source (local file, Google Drive, or URL) into a Pandas DataFrame for further analysis.\n",
    "\n",
    "1. **URL Configuration**\n",
    "    - This specifies the location of the dataset to be loaded. You should **choose one** of the following options:\n",
    "        - **From your computer**: Uncomment the line with the local path to load the dataset from your local machine.\n",
    "        - **From your Google Drive using Google Colab**: Uncomment the lines to mount your Google Drive and specify the path to the dataset in your Google Drive.\n",
    "        - **From a URL on GitHub**: This is the default choice. Uncomment the line with the URL to load the dataset directly from a GitHub repository.\n",
    "\n",
    "2. **Data Loading Parameters**\n",
    "    - Uses `pd.read_csv()` with specific parameters:\n",
    "        - `usecols`: Loads only the columns specified in `use_cols` for memory efficiency\n",
    "        - `encoding='utf-8'`: Handles special characters in the dataset. This is suitable for most languages and special characters like ñ, €, ®. Other alternative encodings include:\n",
    "        - `encoding='utf-16'`: Supports multilingual characters, uses 2 Bytes per character.\n",
    "        - `encoding='utf-32'`: Like utf-16 but uses 4 Bytes per character, suitable for full Unicode range.\n",
    "        - `encoding='latin-1'`: Handles Western European characters (ISO-8859-1), such as ñ, ß, € without throwing decode errors.\n",
    "        - `encoding='big5'`: Traditional Chinese encoding used in Taiwan and Hong Kong.\n",
    "        - `encoding='shift_jis'`: Japanese character encoding used on Windows.\n",
    "        - You can try different encodings if you encounter the `UnicodeDecodeError` while reading a file. This is useful in cases where the business has branches across different countries and the dataset contains characters from multiple languages.\n",
    "        - `nrows=200000`: Limits the number of rows loaded to 200,000. This can be reduced or increased based on the available memory and the size of the dataset.\n",
    "    - The data is then stored in a `Pandas` DataFrame for further analysis\n",
    "    - This selective loading approach helps manage memory usage and focuses the analysis on the relevant features for the design of the model."
   ]
  },
  {
   "cell_type": "code",
   "id": "fbd4307324fa0888",
   "metadata": {},
   "source": [
    "# Option 1: From your computer\n",
    "# Uncomment the following line to load the data from your computer.\n",
    "# url = './data/subscription_churn.csv'\n",
    "\n",
    "# Option 2: From your Google Drive using Google Colab:\n",
    "# Uncomment the following lines to mount your Google Drive and load the data using Google Colab.\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# url = '/content/drive/My Drive/Colab Notebooks/data/subscription_churn.csv'\n",
    "\n",
    "# Option 3: From a URL on GitHub\n",
    "# Uncomment the following line to load the data from a URL on GitHub.\n",
    "url = 'https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/data/subscription_churn.csv'\n",
    "\n",
    "subscription_churn_data = pd.read_csv(url)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d300d4798c43d6a3",
   "metadata": {},
   "source": [
    "## Step 3: Initial Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "id": "33751daa7118183d",
   "metadata": {},
   "source": [
    "print(\"\\n*1* The number of observations and variables\")\n",
    "display(subscription_churn_data.shape)\n",
    "\n",
    "print(\"\\n*2* The data types:\")\n",
    "display(subscription_churn_data.info())\n",
    "\n",
    "print(\"\\n*3* The summary of the numeric columns:\")\n",
    "display(subscription_churn_data.describe())\n",
    "\n",
    "print(\"\\n*4* The whole dataset:\")\n",
    "display(subscription_churn_data)\n",
    "\n",
    "print(\"\\n*5* The first 5 rows in the dataset:\")\n",
    "display(subscription_churn_data.head())\n",
    "\n",
    "print(\"\\n*6* Percentage distribution for each category\")\n",
    "print(\"\\nNumber of observations per class:\")\n",
    "print(\"Frequency counts:\\n\", subscription_churn_data['renew'].value_counts())\n",
    "print(\"\\nPercentages:\\n\", subscription_churn_data['renew'].value_counts(normalize=True) * 100, \"%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dcc56284712a2ee",
   "metadata": {},
   "source": [
    "### Measures of Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28aaecda5b9ed2d",
   "metadata": {},
   "source": [
    "#### Variance of numeric columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c3f94b921b94c",
   "metadata": {},
   "source": [
    "**Selection of numeric columns**\n",
    "- The code selects columns with numeric data types (`int64` and `float64`) that can be subjected to mathematica or statistical functions.\n",
    "- This is done using `select_dtypes()` method of the DataFrame, which filters columns based on their data types."
   ]
  },
  {
   "cell_type": "code",
   "id": "90a05c74f7a09291",
   "metadata": {},
   "source": [
    "numeric_cols = subscription_churn_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(\"\\nVariance of the numeric columns:\")\n",
    "print(subscription_churn_data[numeric_cols].var())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d431c9759d99ac60",
   "metadata": {},
   "source": [
    "#### Standard deviation of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "c2d58c4a09143db0",
   "metadata": {},
   "source": [
    "print(\"\\nStandard deviation of the numeric columns:\")\n",
    "print(subscription_churn_data[numeric_cols].std())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7bdae8bbdf990de",
   "metadata": {},
   "source": [
    "#### Kurtosis of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "a9b9a199cd9b47ec",
   "metadata": {},
   "source": [
    "print(\"\\nFisher Kurtosis of numeric columns:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive kurtosis indicates heavier tails (more outliers) than what is expected in a normal distribution - leptokurtic\")\n",
    "print(\"→ Negative kurtosis indicates lighter tails (less outliers) than what is expected in a normal distribution - platykurtic\")\n",
    "print(\"→ A normal distribution has kurtosis of 0 - mesokurtic\")\n",
    "print(\"\\nKurtosis values:\")\n",
    "print(subscription_churn_data[numeric_cols].apply(lambda x: kurtosis(x, fisher=True)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "56096ca95ed9a585",
   "metadata": {},
   "source": [
    "#### Skewness of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "dacf4bed4488d8cd",
   "metadata": {},
   "source": [
    "print(\"\\nSkewness of numeric columns:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive skewness indicates a long right tail (right-skewed distribution)\")\n",
    "print(\"→ Negative skewness indicates a long left tail (left-skewed distribution)\")\n",
    "print(\"→ Skewness close to 0 indicates a symmetric distribution\")\n",
    "print(\"\\nSkewness values:\")\n",
    "print(subscription_churn_data[numeric_cols].apply(lambda x: skew(x)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29fc02a83f2370e4",
   "metadata": {},
   "source": [
    "### Measures of Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b71a2649720c2",
   "metadata": {},
   "source": [
    "#### Covariance matrix of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "id": "273ac548c820ef4f",
   "metadata": {},
   "source": [
    "print(\"\\nCovariance matrix of numeric features:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive values indicate that variables move in the same direction\")\n",
    "print(\"→ Negative values indicate that variables move in opposite directions\")\n",
    "print(\"→ Values close to 0 indicate little to no linear relationship\")\n",
    "print(\"\\nCovariance values:\")\n",
    "display(subscription_churn_data[numeric_cols].cov())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c16e94be67546ef",
   "metadata": {},
   "source": [
    "#### Correlation matrix of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "id": "635d80947c098933",
   "metadata": {},
   "source": [
    "print(\"\\nSpearman's rank correlation matrix of numeric features:\")\n",
    "spearman_corr = subscription_churn_data[numeric_cols].corr(method='spearman')\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Values range from -1 to +1\")\n",
    "print(\"→ +1 indicates perfect positive correlation\")\n",
    "print(\"→ -1 indicates perfect negative correlation\")\n",
    "print(\"→ 0 indicates no correlation\")\n",
    "print(\"\\nCorrelation values:\")\n",
    "display(spearman_corr)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7fada93113841773",
   "metadata": {},
   "source": [
    "### Basic visualization of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25358dda54ee12f0",
   "metadata": {},
   "source": [
    "- `n_cols = 3` Sets the number of plots per row to 3\n",
    "- `n_rows = (len(numeric_cols) // n_cols) + (1 if len(numeric_cols) % n_cols else 0)` Calculates the number of rows needed based on the number of numeric columns and the number of columns per row.\n",
    "- `plt.figure(figsize=(12, 5 * n_rows))` Sets the figure size to be wider and taller based on the number of rows.\n",
    "- `for i, col in enumerate(numeric_cols, 1):` Iterates over each numeric column (`numeric_cols`), starting the index at 1. `enumerate(numeric_cols, 1)` returns pairs of (index, value) for each item in the list. The 1 means that the index will start from 1, e.g., (1, 'Days for shipping (real)'), (2, 'Days for shipment (scheduled)'), etc.\n",
    "- `plt.subplot(n_rows, n_cols, i)` Creates a subplot in a grid layout with `n_rows` rows and `n_cols` columns, placing the current plot in the `i`-th position.\n",
    "- `sns.histplot(data=profit_per_product, x=col)` Plots a histogram for the current numeric column using Seaborn's `histplot` function.\n",
    "- `sns.boxplot(data=profit_per_product, y=col)` Plots a box plot for the current numeric column using Seaborn's `boxplot` function.\n",
    "- `sns.despine(right=True, top=True)` Removes the right and top spines (borders) of the plot for a cleaner look.\n",
    "- `plt.title(f'Distribution of {col}')` Sets the title of the current subplot to indicate which column's distribution is being shown.\n",
    "- `plt.grid(axis='y', alpha=0.2)` Adds a grid to the y-axis with a transparency level of 0.2 for better visibility.\n",
    "- `plt.grid(axis='x', visible=False)` Hides the grid for the x-axis to reduce clutter and increase the data-to-ink ratio.\n",
    "- `plt.tight_layout()` Adjusts the spacing between subplots to prevent overlap and ensure a clean layout.\n",
    "- `plt.show()` Displays the entire figure with all subplots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869286f15cb3fd25",
   "metadata": {},
   "source": [
    "#### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "id": "500183e9e4cbb682",
   "metadata": {},
   "source": [
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) // n_cols) + (1 if len(numeric_cols) % n_cols else 0)\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.histplot(data=subscription_churn_data, x=col)\n",
    "    sns.despine(right=True, top=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.grid(axis='y', alpha=0.2)\n",
    "    plt.grid(axis='x', visible=False)\n",
    "plt.tight_layout()  # Adjust spacing\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f0e5a41b449e393c",
   "metadata": {},
   "source": [
    "#### Box plots"
   ]
  },
  {
   "cell_type": "code",
   "id": "9b43a3b0b5b18003",
   "metadata": {},
   "source": [
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) // n_cols) + (1 if len(numeric_cols) % n_cols else 0)\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.boxplot(data=subscription_churn_data, y=col)\n",
    "    sns.despine(right=True, top=True, bottom=True)\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "    plt.grid(axis='y', alpha=0.2)\n",
    "    plt.grid(axis='x', visible=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbd0fb4a3b320afc",
   "metadata": {},
   "source": [
    "#### Missing data plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bf89fc73a6994",
   "metadata": {},
   "source": [
    "- This visualization helps to quickly identify which columns have missing values and the extent of the missing data. The heatmap will show yellow for missing values and purple for present values, making it easy to spot patterns of missingness. This is useful for understanding the completeness of the dataset and deciding how to handle missing values in subsequent analysis.\n",
    "- The code uses `Seaborn`'s `heatmap()` function to visualize missing data in the DataFrame.\n",
    "- The code also uses the `isnull()` method to create a boolean DataFrame indicating where values are missing (True) or present (False).\n",
    "- `yticklabels=False` hides the y-axis labels to reduce clutter and increase the data-to-ink ratio.\n",
    "- `cbar=False` removes the color bar, which is not necessary for this plot.\n",
    "- `cmap='viridis'` sets the color map to 'viridis' which is a perceptually uniform color map suitable for visualizing missing data; yellow represents missing values, while purple represents present values.\n",
    "- `plt.title('Missing Data')` sets the title of the plot to 'Missing Data'\n",
    "- `plt.show()` displays the plot."
   ]
  },
  {
   "cell_type": "code",
   "id": "215207867c87e1be",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(subscription_churn_data.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "plt.title('Missing Data')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b6b2ca481c8c912a",
   "metadata": {},
   "source": [
    "#### Correlation heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d034f56dc2cf1077",
   "metadata": {},
   "source": [
    "- This visualization helps to quickly identify relationships between numeric features. The heatmap will show the strength and direction of correlations, with colors indicating positive (red) or negative (blue) correlations. This is useful for understanding how features relate to each other and can inform feature selection or feature engineering in subsequent analysis.\n",
    "- The code uses `Searborn`'s `heatmap()` function to visualize the Spearman correlation matrix of the numeric features in the DataFrame.\n",
    "- `annot=True` adds the correlation values as annotations on the heatmap.\n",
    "- `cmap='coolwarm'` sets the color map to 'coolwarm' which provides a gradient from blue (negative correlation) to red (positive correlation).\n",
    "- `center=0` centers the color map at 0, which is useful for visualizing both positive and negative correlations."
   ]
  },
  {
   "cell_type": "code",
   "id": "ca8f525b280a20f7",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8aeb356c2849574e",
   "metadata": {},
   "source": [
    "#### Scatter plot matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a3cac40bb253c0",
   "metadata": {},
   "source": [
    "- This visualization helps to quickly identify relationships between pairs of numeric features. The scatter plot matrix will show scatter plots for each pair of numeric features, allowing for visual inspection of relationships, trends, and potential outliers. This is useful for understanding how features interact with each other and can inform feature selection or feature engineering in subsequent analysis.\n",
    "- The code uses `Seaborn`'s `pairplot()` function to create a scatter plot matrix of the numeric features in the DataFrame\n",
    "- `plt.suptitle('Scatter Plot Matrix', y=1.02)` Adds a centered title above all subplots (or the single plot). `y=1.02` Moves the title upward by 2% of the figure height (default is y=1.0). This is done to prevent overlap in the subplot titles."
   ]
  },
  {
   "cell_type": "code",
   "id": "a19355945eb2153d",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.pairplot(subscription_churn_data[numeric_cols])\n",
    "plt.suptitle('Scatter Plot Matrix', y=1.02)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "abd1804c1012a75f",
   "metadata": {},
   "source": [
    "## Step 4: Data preprocessing and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1518e6e06cbf3d",
   "metadata": {},
   "source": [
    "### Create X and y datasets for the features and target variable respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79852b72650a656",
   "metadata": {},
   "source": [
    "`X = ...`\n",
    "* Separates the data such that the data frame called `X` contains only the features (independent variables or predictors)\n",
    "\n",
    "`y = ...`\n",
    "* Separates the data such that the data frame called `y` contains only the target (dependent variable or outcome)"
   ]
  },
  {
   "cell_type": "code",
   "id": "3aa17fe05ee20397",
   "metadata": {},
   "source": [
    "X = subscription_churn_data[['monthly_fee','customer_age','support_calls']]\n",
    "y = subscription_churn_data['renew']\n",
    "\n",
    "print(\"\\nThe number of observations and variables in the features dataset\")\n",
    "print(X.shape)\n",
    "print(\"\\nThe columns in the features dataset\")\n",
    "print(X.columns)\n",
    "\n",
    "print(\"\\nThe number of observations and variables in the target dataset\")\n",
    "print(y.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4f906dc8d67ccca0",
   "metadata": {},
   "source": [
    "### Train‑test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ee750",
   "metadata": {},
   "source": [
    "- `train_test_split` is a function from scikit-learn that splits your dataset into two parts: one for training the model and one for testing it.\n",
    "- `X` is your feature data (inputs), and `y` is your target data (outputs/labels).\n",
    "- `test_size=0.3` means 30% of the data in both `X` and `y` will be used for testing, and the remaining 70% in both `X` and `y` for training.\n",
    "- `random_state=53` sets a seed for the random number generator, ensuring that the split is reproducible (you get the same split every time you run the code).\n",
    "\n",
    "- The `train_test_split` function returns four objects:\n",
    "  - `X_train`: features for training\n",
    "  - `X_test`: features for testing\n",
    "  - `y_train`: labels for training\n",
    "  - `y_test`: labels for testing\n",
    "\n",
    "**Why:**  \n",
    "Splitting the data this way allows you to train your model on one part of the data and evaluate its performance on unseen data, which helps prevent overfitting and gives an objective measure of the model's accuracy.\n",
    "\n",
    "*Analogy:* This is similar to how a student learning a subject is not exposed to only one past paper that they can memorize. If they memorize the past paper and the exam assesses them on a different set of questions, then their performance in the exam will not be the same as their performance in the memorized past paper."
   ]
  },
  {
   "cell_type": "code",
   "id": "73c26aeb2303ff74",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=53\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2a814bce602824e",
   "metadata": {},
   "source": [
    "## Step 5: Design the decision tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baad5d4",
   "metadata": {},
   "source": [
    "- `model = DecisionTreeClassifier(criterion=\"gini\", random_state=53)`\n",
    "  - This creates an instance of a decision tree classifier using the CART algorithm.\n",
    "  - **criterion=\"gini\"**: Specifies that the tree should use the Gini impurity measure to decide how to form the splits in the tree.\n",
    "  - **random_state=53**: Ensures reproducibility by setting the random seed.\n",
    "\n",
    "- `model.fit(X_train, y_train)`\n",
    "  - This trains (fits) the decision tree classifier on the training data (`X_train` for features, `y_train` for the target).\n",
    "  - This step therefore builds the decision tree model so it can learn patterns from the training data and later make predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "id": "8eaaa43518a947e3",
   "metadata": {},
   "source": [
    "# Using Gini impurity by default\n",
    "decisiontree_model = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    random_state=53,\n",
    "    max_depth=4)\n",
    "decisiontree_model.fit(X_train, y_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3b8feab7b12283e0",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a653c7d",
   "metadata": {},
   "source": [
    "`y_pred = decisiontree_model.predict(X_test)`\n",
    "\n",
    "- This uses the trained decision tree classifier (`decisiontree_model`) to predict the labels for the test set features (`X_test`). This gives you the model’s predictions on data it has not seen before, which is necessary for evaluating its performance.\n",
    "\n",
    "`print('The decision tree model\\'s performance metrics:\\n', classification_report(y_test, y_pred))`\n",
    "- This prints a detailed classification report comparing the true labels (`y_test`) to the predicted labels (`y_pred`). The report includes precision, recall, F1-score, and support for each class, enabling you to understand how well the model performs.\n",
    "- It shows the performance metrics for a model that predicts two classes:\n",
    "    - Class 0\n",
    "    - Class 1\n",
    "\n",
    "- There are 300 items tested:\n",
    "    - Class 0 has 56 items\n",
    "    - Class 1 has 244 items\n",
    "\n",
    "| Term             | Meaning                                                                                                                             |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Precision**    | Out of all items the model said are class X, how many are actually class X?                                                         |\n",
    "| **Recall**       | Out of all actual items in class X, how many did the model correctly find?                                                          |\n",
    "| **F1-score**     | A balance between precision and recall such  that a higher value means better balance.                                              |\n",
    "| **Support**      | The number of actual items in that class.                                                                                           |\n",
    "| **Macro avg**    | The average of precision, recall, and F1-score for both classes, treating them equally.                                             |\n",
    "| **Weighted avg** | The average of precision, recall, and F1-score, but weighted by how many samples are in each class (so class 1 has more influence). |\n",
    "\n",
    "- The results show that the model is much better at predicting class 1 than class 0, and overall gets **82%** of predictions correct. This may be because there are more class 1 cases in the data.\n",
    "- It is an example of a model that is biased towards the majority class (class 1) and may not perform well in the minority class (class 0). This is a common issue in classification problems, especially when the **classes are imbalanced**."
   ]
  },
  {
   "cell_type": "code",
   "id": "d35f4acf0fa0c747",
   "metadata": {},
   "source": [
    "y_pred = decisiontree_model.predict(X_test)\n",
    "\n",
    "print('The decision tree model\\'s performance metrics:\\n', classification_report(y_test, y_pred))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "98ea69396092a834",
   "metadata": {},
   "source": [
    "## Step 7: Visualize the Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a117f71",
   "metadata": {},
   "source": [
    "`plt.figure(figsize=(12, 8))`\n",
    "- This creates a new matplotlib figure with a size of 12 inches by 8 inches to ensure that the decision tree plot is large and readable.\n",
    "\n",
    "`plot_tree(...)`\n",
    "- Plots the trained decision tree (`decisiontree_model`).\n",
    "    - `feature_names=['monthly_fee','customer_age','support_calls']`: Labels the tree’s nodes with the feature names.\n",
    "    - `class_names= ['Cancel', 'Renew']`: Labels the leaves with the class names.\n",
    "    - `filled=True`: Colors the nodes based on the class for better visualization.\n",
    "    - `fontsize=8`: Sets the font size for the text in the plot to 8 for better readability.\n",
    "    - `max_depth=4`: Limits the depth of the tree to 4 levels for better readability.\n",
    "- This visually shows how the decision tree splits the data and makes decisions.\n",
    "\n",
    "`plt.title(\"A Decision Tree Classifier using Gini Impurity (CART)\")`\n",
    "- Sets the title of the plot to provide context for the visualization.\n",
    "\n",
    "`plt.show()`\n",
    "- This is used to display the plot in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "id": "d5ff85d6aca9a7a6",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "plot_tree(\n",
    "    decisiontree_model,\n",
    "    feature_names=['monthly_fee','customer_age','support_calls'],\n",
    "    class_names= ['Cancel', 'Renew'],\n",
    "    filled=True,\n",
    "    fontsize=8,\n",
    "    max_depth=4)\n",
    "plt.title(\"Decision Tree using the Gini Impurity (CART) Splitting Criterion\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa0e5e96199d2f62",
   "metadata": {},
   "source": [
    "## Step 8: Make predictions on new data and save the results for reporting in Power BI"
   ]
  },
  {
   "cell_type": "code",
   "id": "7374f95e",
   "metadata": {},
   "source": [
    "# Example: Using the trained model to make predictions on new or unseen data.\n",
    "# Create a DataFrame with new customer data (replace values as needed)\n",
    "new_data = pd.DataFrame({\n",
    "    'monthly_fee': [50, 80],\n",
    "    'customer_age': [25, 40],\n",
    "    'support_calls': [2, 0]\n",
    "})\n",
    "\n",
    "# Predict whether the customers will renew or cancel their subscription\n",
    "predictions = decisiontree_model.predict(new_data)\n",
    "print(\"Predictions for new data:\", predictions)\n",
    "\n",
    "label_map = {0: 'Cancel', 1: 'Renew'}\n",
    "predicted_labels = [label_map[p] for p in predictions]\n",
    "print(\"Predicted labels for new data:\", predicted_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fbdfb3185f5326b5",
   "metadata": {},
   "source": [
    "- This section demonstrates how to use the trained decision tree model to make predictions on new data and save the results for reporting in Power BI.\n",
    "- It loads new data, processes it similarly to the training data, makes predictions, and saves the results to a CSV file for further analysis or reporting.\n",
    "- The new data is expected to have the same structure as the training data, with the same features used for training the model.\n",
    "- The predictions include whether the customers are likely to renew or cancel their subscription, along with the probabilities of each outcome.\n",
    "- The results are saved to a CSV file, which can then be imported into Power BI for visualization and reporting.\n",
    "- This is useful for businesses to understand customer behavior and make informed decisions based on the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "id": "c81e2b151e0a667d",
   "metadata": {},
   "source": [
    "# Load new data from the URL\n",
    "url = 'https://github.com/course-files/RegressionAndClassification/raw/refs/heads/main/data/subscription_churn_new_data.csv'\n",
    "\n",
    "new_data = pd.read_csv(url)\n",
    "\n",
    "# Make predictions\n",
    "predictions = decisiontree_model.predict(new_data)\n",
    "probabilities = decisiontree_model.predict_proba(new_data)\n",
    "\n",
    "# Add predictions and probabilities to the original dataframe\n",
    "new_data['Renew_Probability_Class_0'] = probabilities[:, 0]  # Probability of cancellation\n",
    "new_data['Renew_Probability_Class_1'] = probabilities[:, 1]  # Probability of renewal\n",
    "new_data['Predicted_Renew'] = predictions\n",
    "\n",
    "print(\"\\nThe new data with predictions:\")\n",
    "display(new_data)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "# Option 1: Save to your computer\n",
    "# Uncomment the following line to save the file to your computer.\n",
    "# output_file = './data/subscription_churn_predicted_data.csv'\n",
    "\n",
    "# Option 2: Save to your Google Drive using Google Colab:\n",
    "# Uncomment the following lines to mount your Google Drive and save the data using Google Colab.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "output_file = '/content/drive/My Drive/Colab Notebooks/data/subscription_churn_predicted_data.csv'\n",
    "\n",
    "new_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Display the first few rows of the results\n",
    "print(\"First few rows of the data with predictions:\")\n",
    "display(new_data.head(20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af97034d481c83eb",
   "metadata": {},
   "source": [
    "# Business Insights\n",
    "- The model's predictions can be used to identify customers who are likely to churn, allowing the marketing and sales teams to take proactive measures to retain them.\n",
    "- The predictions and probabilities for new customer data have been saved to a CSV file, which can be imported into Power BI for reporting.\n",
    "- The decision tree visualization provides insights into the key features that influence customer churn. These include monthly fee, customer age, and support calls.\n",
    "- The model's accuracy can be further improved by tuning hyperparameters, using more advanced algorithms, or incorporating additional features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

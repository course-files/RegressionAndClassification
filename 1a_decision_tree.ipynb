{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98779557a508068a",
   "metadata": {},
   "source": [
    "# Classification using the CART Algorithm (a decision tree classifier) and the Gini Impurity\n",
    "\n",
    "|                  |                                                                                                                                                                                                     |\n",
    "|:-----------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Course Codes** | BBT 4106, BCM 3104, and BFS 4102                                                                                                                                                                    |\n",
    "| **Course Names** | BBT 4106: Business Intelligence I (Week 10-12 of 13),<br/>BCM 3104: Business Intelligence and Data Analytics (Week 10-12 of 13) and<br/>BFS 4102: Advanced Business Data Analytics (Week 4-6 of 13) |\n",
    "| **Semester**     | April to July 2025                                                                                                                                                                                  |\n",
    "| **Lecturer**     | Allan Omondi                                                                                                                                                                                        |\n",
    "| **Contact**      | aomondi@strathmore.edu                                                                                                                                                                              |\n",
    "| **Note**         | The lecture contains both theory and practice. This notebook forms part of the practice. This is intended for educational purpose only.                                                             |\n",
    "\n",
    "**Business context**: A business has a strategic objective to *reduce customer churn to 10% by the end of the current financial year*. The lagging KPI in the customer perspective of the business' performance is the churn rate whereas its leading KPI is the number of support calls. The business would like to predict whether a customer will renew their subscription so that the marketing and sales teams can intervene early and avoid losing customers.\n",
    "\n",
    "**Dataset**: The synthetic dataset used in this notebook is based on the **\"Subscription Churn\"** dataset. It contains 1,000 observations of customer data with the following features and target.\n",
    "\n",
    "| **Type**    | **Name**        | **Description**                                                                                       |\n",
    "|:------------|-----------------|:------------------------------------------------------------------------------------------------------|\n",
    "| **Feature** | `monthly_fee`   | Monthly fee paid by the customer                                                                      |\n",
    "| **Feature** | `customer_age`  | Age of the customer in years                                                                          |\n",
    "| **Feature** | `support_calls` | Number of support calls made by the customer                                                          |\n",
    "| **Target**  | `renew`         | A categorical variable that indicates if the customer renewed (1) or cancelled (0) their subscription |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f4645b58c95cc",
   "metadata": {},
   "source": "## Step 1: Import the necessary libraries"
  },
  {
   "cell_type": "markdown",
   "id": "bc8b5b4f",
   "metadata": {},
   "source": [
    "1. **Data Manipulation Libraries**\n",
    "    - `pandas as pd`: For loading the dataset, creating and managing DataFrames, data manipulation and analysis using DataFrames\n",
    "\n",
    "2. **Machine Learning Libraries**\n",
    "    - `DecisionTreeClassifier`: A class from scikit-learn that implements the CART (Classification and Regression Trees) algorithm for building decision tree models.\n",
    "    - `plot_tree`: A function from scikit-learn’s tree module that visualizes the decision tree structure.\n",
    "    - `train_test_split`: A function from scikit-learn’s model_selection module that splits the dataset into training and testing sets.\n",
    "    - `classification_report`: A function from scikit-learn’s metrics module used to evaluate the performance of the classifier. It gives detailed metrics such as precision, recall, f1-score, and support for each class.\n",
    "\n",
    "3. **Statistical Analysis (SciPy)**\n",
    "    - `kurtosis`: Measures the \"tailedness\" of data distribution\n",
    "    - `skew`: Measures the asymmetry of data distribution\n",
    "\n",
    "4. **Visualization Libraries**\n",
    "    - `matplotlib.pyplot as plt`: For basic plotting functionality\n",
    "    - `seaborn as sns`: For enhanced statistical visualizations\n",
    "\n",
    "5. **Warnings Management**\n",
    "    - `warnings`: Controls warning messages\n",
    "    - `warnings.filterwarnings('ignore')`: Suppresses warning messages for cleaner output\n",
    "    - Used to suppress warnings that may arise during the execution of the code. Even though it is not necessary for the code to run, it helps in keeping the output clean and focused on the results."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa681e97ffbe68a9",
   "metadata": {},
   "source": [
    "## Step 2: Load and Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eef830",
   "metadata": {},
   "source": [
    "`url =`\n",
    "- Specifies the location where the `.csv` dataset can be found\n",
    "\n",
    "`subscription_churn_data = pd.read_csv(url)`\n",
    "-Used to load the dataset into the data frame called `subscription_churn_data`\n",
    "\n",
    "`print(\"\\nThe dimensions (number of observations and number of dimensions):\")`\n",
    "`print(subscription_churn_data.shape)`\n",
    "* Prints the string \"The dimensions (number of observations and number of dimensions):\" using the `print()` function and then uses the `shape` attribute to print the number of rows and columns in the data frame. This gives you an idea of how many observations (rows) and dimensions (columns) are present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "id": "fbd4307324fa0888",
   "metadata": {},
   "source": [
    "# If you are using Google Colab, uncomment the following lines to mount your Google Drive and load the new data from there.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# url = '/content/drive/My Drive/Colab Notebooks/data/DataCoSupplyChainDataset.csv'\n",
    "\n",
    "# url = './data/subscription_churn.csv'\n",
    "url = 'https://raw.githubusercontent.com/course-files/RegressionAndClassification/refs/heads/main/data/subscription_churn.csv'\n",
    "subscription_churn_data = pd.read_csv(url)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3: Initial Exploratory Data Analysis (EDA)",
   "id": "d300d4798c43d6a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n*1* The number of observations and variables\")\n",
    "display(subscription_churn_data.shape)\n",
    "\n",
    "print(\"\\n*2* The data types:\")\n",
    "display(subscription_churn_data.info())\n",
    "\n",
    "print(\"\\n*3* The summary of the numeric columns:\")\n",
    "display(subscription_churn_data.describe())\n",
    "\n",
    "print(\"\\n*4* The whole dataset:\")\n",
    "display(subscription_churn_data)\n",
    "\n",
    "print(\"\\n*5* The first 5 rows in the dataset:\")\n",
    "display(subscription_churn_data.head())\n",
    "\n",
    "print(\"\\n*6* Percentage distribution for each category\")\n",
    "print(\"\\nNumber of observations per class:\")\n",
    "print(\"Frequency counts:\\n\", subscription_churn_data['renew'].value_counts())\n",
    "print(\"\\nPercentages:\\n\", subscription_churn_data['renew'].value_counts(normalize=True) * 100, \"%\")"
   ],
   "id": "33751daa7118183d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Measures of Distribution",
   "id": "dcc56284712a2ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Variance of numeric columns",
   "id": "d28aaecda5b9ed2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Selection of numeric columns**\n",
    "- The code selects columns with numeric data types (`int64` and `float64`) that can be subjected to mathematica or statistical functions.\n",
    "- This is done using `select_dtypes()` method of the DataFrame, which filters columns based on their data types."
   ],
   "id": "c68c3f94b921b94c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_cols = subscription_churn_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(\"\\nVariance of the numeric columns:\")\n",
    "print(subscription_churn_data[numeric_cols].var())"
   ],
   "id": "90a05c74f7a09291",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Standard deviation of numeric columns",
   "id": "d431c9759d99ac60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nStandard deviation of the numeric columns:\")\n",
    "print(subscription_churn_data[numeric_cols].std())"
   ],
   "id": "c2d58c4a09143db0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Kurtosis of numeric columns",
   "id": "c7bdae8bbdf990de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nFisher Kurtosis of numeric columns:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive kurtosis indicates heavier tails (more outliers) than what is expected in a normal distribution - leptokurtic\")\n",
    "print(\"→ Negative kurtosis indicates lighter tails (less outliers) than what is expected in a normal distribution - platykurtic\")\n",
    "print(\"→ A normal distribution has kurtosis of 0 - mesokurtic\")\n",
    "print(\"\\nKurtosis values:\")\n",
    "print(subscription_churn_data[numeric_cols].apply(lambda x: kurtosis(x, fisher=True)))"
   ],
   "id": "a9b9a199cd9b47ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Skewness of numeric columns",
   "id": "56096ca95ed9a585"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nSkewness of numeric columns:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive skewness indicates a long right tail (right-skewed distribution)\")\n",
    "print(\"→ Negative skewness indicates a long left tail (left-skewed distribution)\")\n",
    "print(\"→ Skewness close to 0 indicates a symmetric distribution\")\n",
    "print(\"\\nSkewness values:\")\n",
    "print(subscription_churn_data[numeric_cols].apply(lambda x: skew(x)))"
   ],
   "id": "dacf4bed4488d8cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Measures of Relationship",
   "id": "29fc02a83f2370e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Covariance matrix of numeric features",
   "id": "2e7b71a2649720c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nCovariance matrix of numeric features:\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Positive values indicate that variables move in the same direction\")\n",
    "print(\"→ Negative values indicate that variables move in opposite directions\")\n",
    "print(\"→ Values close to 0 indicate little to no linear relationship\")\n",
    "print(\"\\nCovariance values:\")\n",
    "display(subscription_churn_data[numeric_cols].cov())"
   ],
   "id": "273ac548c820ef4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Correlation matrix of numeric features",
   "id": "5c16e94be67546ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\nSpearman's rank correlation matrix of numeric features:\")\n",
    "spearman_corr = subscription_churn_data[numeric_cols].corr(method='spearman')\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"→ Values range from -1 to +1\")\n",
    "print(\"→ +1 indicates perfect positive correlation\")\n",
    "print(\"→ -1 indicates perfect negative correlation\")\n",
    "print(\"→ 0 indicates no correlation\")\n",
    "print(\"\\nCorrelation values:\")\n",
    "display(spearman_corr)"
   ],
   "id": "635d80947c098933",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Basic visualization of the data",
   "id": "7fada93113841773"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `n_cols = 3` Sets the number of plots per row to 3\n",
    "- `n_rows = (len(numeric_cols) // n_cols) + (1 if len(numeric_cols) % n_cols else 0)` Calculates the number of rows needed based on the number of numeric columns and the number of columns per row.\n",
    "- `plt.figure(figsize=(12, 5 * n_rows))` Sets the figure size to be wider and taller based on the number of rows.\n",
    "- `for i, col in enumerate(numeric_cols, 1):` Iterates over each numeric column (`numeric_cols`), starting the index at 1. `enumerate(numeric_cols, 1)` returns pairs of (index, value) for each item in the list. The 1 means that the index will start from 1, e.g., (1, 'Days for shipping (real)'), (2, 'Days for shipment (scheduled)'), etc.\n",
    "- `plt.subplot(n_rows, n_cols, i)` Creates a subplot in a grid layout with `n_rows` rows and `n_cols` columns, placing the current plot in the `i`-th position.\n",
    "- `sns.histplot(data=supply_chain_data, x=col)` Plots a histogram for the current numeric column using Seaborn's `histplot` function.\n",
    "- `sns.boxplot(data=supply_chain_data, y=col)` Plots a box plot for the current numeric column using Seaborn's `boxplot` function.\n",
    "- `sns.despine(right=True, top=True)` Removes the right and top spines (borders) of the plot for a cleaner look.\n",
    "- `plt.title(f'Distribution of {col}')` Sets the title of the current subplot to indicate which column's distribution is being shown.\n",
    "- `plt.grid(axis='y', alpha=0.2)` Adds a grid to the y-axis with a transparency level of 0.2 for better visibility.\n",
    "- `plt.grid(axis='x', visible=False)` Hides the grid for the x-axis to reduce clutter and increase the data-to-ink ratio.\n",
    "- `plt.tight_layout()` Adjusts the spacing between subplots to prevent overlap and ensure a clean layout.\n",
    "- `plt.show()` Displays the entire figure with all subplots."
   ],
   "id": "25358dda54ee12f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Histograms",
   "id": "869286f15cb3fd25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) // n_cols) + (1 if len(numeric_cols) % n_cols else 0)\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.histplot(data=subscription_churn_data, x=col)\n",
    "    sns.despine(right=True, top=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.grid(axis='y', alpha=0.2)\n",
    "    plt.grid(axis='x', visible=False)\n",
    "plt.tight_layout()  # Adjust spacing\n",
    "plt.show()"
   ],
   "id": "500183e9e4cbb682",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Box plots",
   "id": "f0e5a41b449e393c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) // n_cols) + (1 if len(numeric_cols) % n_cols else 0)\n",
    "\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.boxplot(data=subscription_churn_data, y=col)\n",
    "    sns.despine(right=True, top=True, bottom=True)\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "    plt.grid(axis='y', alpha=0.2)\n",
    "    plt.grid(axis='x', visible=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9b43a3b0b5b18003",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Missing data plot",
   "id": "dbd0fb4a3b320afc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- This visualization helps to quickly identify which columns have missing values and the extent of the missing data. The heatmap will show yellow for missing values and purple for non-missing values, making it easy to spot patterns of missingness. This is useful for understanding the completeness of the dataset and deciding how to handle missing values in subsequent analysis.\n",
    "- The code uses `sns.heatmap()` to visualize missing data in the DataFrame.\n",
    "- The code also uses the `isnull()` method to create a boolean DataFrame indicating where values are missing (True) or present (False).\n",
    "- `yticklabels=False` hides the y-axis labels to reduce clutter.\n",
    "- `cbar=False` removes the color bar, which is not necessary for this plot.\n",
    "- `cmap='viridis'` sets the color map to 'viridis' which is a perceptually uniform color map suitable for visualizing missing data.\n",
    "- `plt.title('Missing Data')` sets the title of the plot to 'Missing Data'\n",
    "- `plt.show()` displays the plot."
   ],
   "id": "846bf89fc73a6994"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(subscription_churn_data.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "plt.title('Missing Data')\n",
    "plt.show()"
   ],
   "id": "215207867c87e1be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Correlation heatmap",
   "id": "b6b2ca481c8c912a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- This visualization helps to quickly identify relationships between numeric features. The heatmap will show the strength and direction of correlations, with colors indicating positive (red) or negative (blue) correlations. This is useful for understanding how features relate to each other and can inform feature selection or feature engineering in subsequent analysis.\n",
    "- The code uses `sns.heatmap()` to visualize the Spearman correlation matrix of the numeric features in the DataFrame.\n",
    "- `annot=True` adds the correlation values as annotations in the heatmap.\n",
    "- `cmap='coolwarm'` sets the color map to 'coolwarm' which provides a gradient from blue (negative correlation) to red (positive correlation).\n",
    "- `center=0` centers the color map at 0, which is useful for visualizing both positive and negative correlations."
   ],
   "id": "d034f56dc2cf1077"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ],
   "id": "ca8f525b280a20f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Scatter plot matrix",
   "id": "8aeb356c2849574e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- This visualization helps to quickly identify relationships between pairs of numeric features. The scatter plot matrix will show scatter plots for each pair of numeric features, allowing for visual inspection of relationships, trends, and potential outliers. This is useful for understanding how features interact with each other and can inform feature selection or feature engineering in subsequent analysis.\n",
    "- The code uses `sns.pairplot()` to create a scatter plot matrix of the numeric features in the DataFrame"
   ],
   "id": "83a3cac40bb253c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.pairplot(subscription_churn_data[numeric_cols])\n",
    "plt.suptitle('Scatter Plot Matrix', y=1.02)\n",
    "plt.show()"
   ],
   "id": "a19355945eb2153d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "abd1804c1012a75f",
   "metadata": {},
   "source": "## Step 4: Data preparation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create X and y datasets for the features and target variable respectively",
   "id": "fd1518e6e06cbf3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`X = pd.DataFrame(subscription_churn_data, columns = ['monthly_fee','customer_age','support_calls'])`\n",
    "* Separates the data such that the data frame called `X` contains only the features (independent variables or predictors)\n",
    "\n",
    "`y = pd.Series(subscription_churn_data['renew'])`\n",
    "* Separates the data such that the data frame called `y` contains only the target (dependent variable or outcome)"
   ],
   "id": "b79852b72650a656"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = pd.DataFrame(subscription_churn_data, columns = ['monthly_fee','customer_age','support_calls'])\n",
    "y = pd.Series(subscription_churn_data['renew'])"
   ],
   "id": "3aa17fe05ee20397",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train‑test split",
   "id": "4f906dc8d67ccca0"
  },
  {
   "cell_type": "markdown",
   "id": "860ee750",
   "metadata": {},
   "source": [
    "- `train_test_split` is a function from scikit-learn that splits your dataset into two parts: one for training the model and one for testing it.\n",
    "- `X` is your feature data (inputs), and `y` is your target data (outputs/labels).\n",
    "- `test_size=0.3` means 30% of the data will be used for testing, and the remaining 70% for training.\n",
    "- `random_state=53` sets a seed for the random number generator, ensuring that the split is reproducible (you get the same split every time you run the code).\n",
    "\n",
    "- The `train_test_split` function returns four objects:\n",
    "  - `X_train`: features for training\n",
    "  - `X_test`: features for testing\n",
    "  - `y_train`: labels for training\n",
    "  - `y_test`: labels for testing\n",
    "\n",
    "**Why:**  \n",
    "Splitting the data this way allows you to train your model on one part of the data and evaluate its performance on unseen data, which helps prevent overfitting and gives a realistic measure of model accuracy.\n",
    "\n",
    "Analogy: This is similar to how a student learning a subject is not exposed to only one past paper that they then memorize. If they memorize the past paper and the exam assesses them on a different set of questions, then their performance in the exam will not be the same as their performance in the memorized past paper."
   ]
  },
  {
   "cell_type": "code",
   "id": "73c26aeb2303ff74",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=53\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2a814bce602824e",
   "metadata": {},
   "source": "## Step 5: Create and Train the CART Decision Tree"
  },
  {
   "cell_type": "markdown",
   "id": "2baad5d4",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- `model = DecisionTreeClassifier(criterion=\"gini\", random_state=53)`\n",
    "  - This creates an instance of a decision tree classifier using the CART algorithm.\n",
    "  - **criterion=\"gini\"**: Specifies that the tree should use the Gini impurity measure to decide splits (the default for CART).\n",
    "  - **random_state=53**: Ensures reproducibility by setting the random seed.\n",
    "\n",
    "- `model.fit(X_train, y_train)`\n",
    "  - This trains (fits) the decision tree classifier on the training data (`X_train` for features, `y_train` for the target).\n",
    "  - This step therefore builds the decision tree model so it can learn patterns from the training data and later make predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "id": "8eaaa43518a947e3",
   "metadata": {},
   "source": [
    "# Using Gini impurity by default\n",
    "decisiontree_model = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    random_state=53,\n",
    "    max_depth=4)\n",
    "decisiontree_model.fit(X_train, y_train)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 6: Evaluate the Model",
   "id": "3b8feab7b12283e0"
  },
  {
   "cell_type": "markdown",
   "id": "7a653c7d",
   "metadata": {},
   "source": [
    "`y_pred = model.predict(X_test)`\n",
    "\n",
    "- This uses the trained decision tree classifier (`model`) to predict the labels for the test set features (`X_test`). This gives you the model’s predictions on data it has not seen before, which is necessary for evaluating its performance.\n",
    "\n",
    "`print(\"Classification Report:\\n\", classification_report(y_test, y_pred))`\n",
    "- This prints a detailed classification report comparing the true labels (`y_test`) to the predicted labels (`y_pred`). The report includes precision, recall, F1-score, and support for each class, enabling you to understand how well the model performs for each category.\n",
    "- It shows the performance metrics for a model that predicts two classes:\n",
    "    - Class 0\n",
    "    - Class 1\n",
    "\n",
    "- There are 300 total items tested:\n",
    "    - Class 0 has 56 items\n",
    "    - Class 1 has 244 items\n",
    "\n",
    "| Term             | Meaning                                                                                                                             |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Precision**    | Out of all items the model said are class X, how many are actually class X?                                                         |\n",
    "| **Recall**       | Out of all actual items in class X, how many did the model correctly find?                                                          |\n",
    "| **F1-score**     | A balance between precision and recall such  that a higher value means better balance.                                              |\n",
    "| **Support**      | The number of actual items in that class.                                                                                           |\n",
    "| **Macro avg**    | The average of precision, recall, and F1-score for both classes, treating them equally.                                             |\n",
    "| **Weighted avg** | The average of precision, recall, and F1-score, but weighted by how many samples are in each class (so class 1 has more influence). |\n",
    "\n",
    "- The results show that the model is much better at predicting class 1 than class 0, and overall gets 75% of predictions correct. This may be because there are more class 1 cases in the data."
   ]
  },
  {
   "cell_type": "code",
   "id": "d35f4acf0fa0c747",
   "metadata": {},
   "source": [
    "y_pred = decisiontree_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "98ea69396092a834",
   "metadata": {},
   "source": "## Step 7: Visualize the Decision Tree"
  },
  {
   "cell_type": "markdown",
   "id": "0a117f71",
   "metadata": {},
   "source": [
    "`plt.figure(figsize=(12, 8))`\n",
    "This creates a new matplotlib figure with a size of 12 inches by 8 inches to ensure that the decision tree plot is large and readable.\n",
    "\n",
    "`plot_tree(model, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)`\n",
    "- Plots the trained decision tree (`model`).\n",
    "    - `feature_names=iris.feature_names`: Labels the tree’s nodes with the feature names.\n",
    "    - `class_names=iris.target_names`: Labels the leaves with the class names.\n",
    "    - `filled=True`: Colors the nodes based on the class for better visualization.\n",
    "- This visually shows how the decision tree splits the data and makes decisions.\n",
    "\n",
    "`plt.title(\"A Decision Tree Classifier using Gini Impurity (CART)\")`\n",
    "- Sets the title of the plot to provide context for the visualization.\n",
    "\n",
    "`plt.show()`\n",
    "- This is used to display the plot in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "id": "d5ff85d6aca9a7a6",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "plot_tree(\n",
    "    decisiontree_model,\n",
    "    feature_names=['monthly_fee','customer_age','support_calls'],\n",
    "    class_names= ['Cancel', 'Renew'],\n",
    "    filled=True,\n",
    "    max_depth=4)\n",
    "plt.title(\"Decision Tree using the Gini Impurity (CART)\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 8: Make predictions on new data and save the results for reporting in Power BI",
   "id": "aa0e5e96199d2f62"
  },
  {
   "cell_type": "code",
   "id": "7374f95e",
   "metadata": {},
   "source": [
    "# Example: Using the trained model to make predictions on new or unseen data.\n",
    "# Create a DataFrame with new customer data (replace values as needed)\n",
    "new_data = pd.DataFrame({\n",
    "    'monthly_fee': [50, 80, 48],\n",
    "    'customer_age': [25, 40, 50],\n",
    "    'support_calls': [2, 0, 1]\n",
    "})\n",
    "\n",
    "# Predict whether these 3 customers will renew or cancel their subscription\n",
    "predictions = decisiontree_model.predict(new_data)\n",
    "print(\"Predictions for new data:\", predictions)\n",
    "\n",
    "label_map = {0: 'Cancel', 1: 'Renew'}\n",
    "predicted_labels = [label_map[p] for p in predictions]\n",
    "print(\"Predicted labels for new data:\", predicted_labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- This section demonstrates how to use the trained decision tree model to make predictions on new data and save the results for reporting in Power BI.\n",
    "- It loads new data, processes it similarly to the training data, makes predictions, and saves the results to a CSV file for further analysis or reporting.\n",
    "- The new data is expected to have the same structure as the training data, with the same features used for training the model.\n",
    "- The predictions include whether the customers are likely to renew or cancel their subscription, along with the probabilities of each outcome.\n",
    "- The results are saved to a CSV file, which can then be imported into Power BI for visualization and reporting.\n",
    "- This is useful for businesses to understand customer behavior and make informed decisions based on the model's predictions."
   ],
   "id": "fbdfb3185f5326b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the new data\n",
    "# If you are using Google Colab, uncomment the following lines to mount your\n",
    "# Google Drive and load the new data from there.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# new_data_file = '/content/drive/My Drive/Colab Notebooks/data/subscription_churn_new_data.csv'\n",
    "\n",
    "# If you are using Google Colab, comment the following line\n",
    "new_data_file = './data/subscription_churn_new_data.csv'\n",
    "\n",
    "new_data = pd.read_csv(new_data_file)\n",
    "\n",
    "# Make predictions\n",
    "predictions = decisiontree_model.predict(new_data)\n",
    "probabilities = decisiontree_model.predict_proba(new_data)\n",
    "\n",
    "# Add predictions and probabilities to the original dataframe\n",
    "new_data['Predicted_Renew'] = predictions\n",
    "new_data['Renew_Probability_Class_0'] = probabilities[:, 0]  # Probability of cancellation\n",
    "new_data['Renew_Probability_Class_1'] = probabilities[:, 1]  # Probability of renewal\n",
    "\n",
    "print(\"\\nThe new data with predictions:\")\n",
    "display(new_data)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "\n",
    "\n",
    "# If you are using Google Colab, uncomment the following lines to save the predicted data to your Google Drive.\n",
    "# output_file = '/content/drive/My Drive/Colab Notebooks/data/subscription_churn_predicted_data.csv'\n",
    "\n",
    "output_file = './data/subscription_churn_predicted_data.csv'\n",
    "new_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Print save confirmation\n",
    "print(f\"\\nPredictions saved to: {output_file}\")"
   ],
   "id": "c81e2b151e0a667d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Business Insights\n",
    "- The model's predictions can be used to identify customers who are likely to churn, allowing the marketing and sales teams to take proactive measures to retain them.\n",
    "- The predictions and probabilities for new customer data have been saved to a CSV file, which can be imported into Power BI for reporting.\n",
    "- The decision tree visualization provides insights into the key features that influence customer churn, such as monthly fee, customer age, and support calls.\n",
    "- The model can be further improved by tuning hyperparameters, using more advanced algorithms, or incorporating additional features."
   ],
   "id": "af97034d481c83eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
